[["index.html", "The Hitchhiker’s Guide to Longitudinal Models Code Companion About", " The Hitchhiker’s Guide to Longitudinal Models Code Companion Ethan M. McCormick, Michelle L. Byrne, John C. Flournoy, Katheryn L. Mills, &amp; Jennifer H. Pfiefer Published: 19 November, 2021 About The following document is a code companion to citation, doi. Some general notes about this code companion: Given the nature of R, there are likely several ways to accomplish what we outline here. This code should not be taken as the definitive one way that data manipulation or model fitting can be accomplished, but rather as a standard pipeline that should hopefully be accessible to new users of R and longitudinal methods more generally. In general, we will include the code used to generate the results. However, in the interest of spending more time on the models and associated syntax, we may not include an in-depth explanation of every function or syntax option. The rmarkdown source files are available in a public github repository for those interested. While the contents of this primer and code companion will focus on implementation in the R environment, links will be provided to other programs where possible. A fair warning: code in other languages will be provided in an arbitrary and capricious manner. This policy should be familiar to the reader, given their experience with the text of the manuscript (and if very unlucky, the first author). "],["01-introduction.html", "Introduction", " Introduction The first thing we can do is run a function that will load the R packages needed to run this code companion, and install them to our machine if they are not already. packages = c(&#39;utils&#39;, &#39;tidyverse&#39;, &#39;downloadthis&#39;, # packages for data management &#39;foreign&#39;, &#39;MplusAutomation&#39;, # packages for writing data &#39;ggplot2&#39;, &#39;sjPlot&#39;, &#39;broom&#39;, # packages for visualization &#39;nlme&#39;, &#39;lme4&#39;, &#39;lmerTest&#39;, # packages for MLMs &#39;mgcv&#39;, &#39;gamm4&#39;, # packages for GAMMs &#39;lavaan&#39;, &#39;semPlot&#39;) # packages for SEMs if (length(setdiff(packages, rownames(installed.packages()))) &gt; 0) { install.packages(setdiff(packages, rownames(installed.packages())), repos = &#39;http://cran.us.r-project.org&#39;) } invisible(lapply(packages, library, character.only = TRUE)) We have automatically generated a downloadable bibliography of the R package versions used in this companion for later reproducibility. knitr::write_bib(c( .packages(), &#39;bookdown&#39;, &#39;knitr&#39;, &#39;rmarkdown&#39; ), &#39;external/hitchhikers-guide-packages.bib&#39;) Download Bibliography file "],["02-canonical.html", "Canonical Models Multilevel Model Generalized Additive Mixed Model Latent Curve Model Latent Change Score Model", " Canonical Models What follows are canonical versions of growth models in each of the four different frameworks. These models represent basic implementations of a linear growth trajectory with random effects for both the intercept and slope, with the exception of the GAMM, where a non-linear spline model is implemented (otherwise it would just re-capitulate the MLM results). We can start by reading in the datasets we will use in this chapter. canonical.wide = utils::read.csv(&#39;data/01-canonical.csv&#39;, header = TRUE) canonical.long = canonical.wide %&gt;% tidyr::pivot_longer(cols = starts_with(&#39;dlpfc&#39;), names_to = c(&#39;.value&#39;, &#39;wave&#39;), names_pattern = &#39;(.+)(.)&#39;) %&gt;% dplyr::mutate(wave = as.numeric(wave) - 1) canonical.gamm = read.csv(&#39;data/01-canonical-gamm.csv&#39;) talk briefly about datasets and show code to output them to mplus filename = &#39;01-canonical&#39; capture.output( MplusAutomation::prepareMplusData(canonical.wide, paste0(&#39;external/&#39;,filename,&#39;.dat&#39;)), file=paste0(&#39;external/&#39;,filename,&#39;_MplusAutomation.txt&#39;)) write.foreign(canonical.long, datafile = paste0(&#39;external/&#39;,filename,&#39;.txt&#39;), codefile = &#39;&#39;, package=&#39;SAS&#39;) ## * Written by R; ## * write.foreign(canonical.long, datafile = paste0(&quot;external/&quot;, ; ## ## DATA rdata ; ## INFILE &quot;external/01-canonical.txt&quot; ## DSD ## LRECL= 28 ; ## INPUT ## id ## wave ## dlpfc ## ; ## RUN; Download SAS files Download Mplus files Multilevel Model mlm.nlme = nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, na.action = na.omit, method = &#39;REML&#39;, data = canonical.long) summary(mlm.nlme) ## Linear mixed-effects model fit by REML ## Data: canonical.long ## AIC BIC logLik ## 3510.473 3541.503 -1749.236 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8120176 (Intr) ## wave 0.2231279 -0.354 ## Residual 0.7024454 ## ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5458598 0.05440921 961 10.032490 0 ## wave 0.1185110 0.02132837 961 5.556492 0 ## Correlation: ## (Intr) ## wave -0.545 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.8835588 -0.5108207 -0.0265644 0.5325893 2.6759419 ## ## Number of Observations: 1304 ## Number of Groups: 342 mlm.lme4 = lme4::lmer(dlpfc ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = canonical.long) summary(mlm.lme4) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: dlpfc ~ 1 + wave + (1 + wave | id) ## Data: canonical.long ## ## REML criterion at convergence: 3498.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.88358 -0.51082 -0.02656 0.53257 2.67596 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.65939 0.8120 ## wave 0.04979 0.2231 -0.35 ## Residual 0.49342 0.7024 ## Number of obs: 1304, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.54586 0.05441 10.032 ## wave 0.11851 0.02133 5.556 ## ## Correlation of Fixed Effects: ## (Intr) ## wave -0.545 mlm.lmerTest = lmerTest::lmer(dlpfc ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = canonical.long) summary(mlm.lmerTest) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: dlpfc ~ 1 + wave + (1 + wave | id) ## Data: canonical.long ## ## REML criterion at convergence: 3498.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.88358 -0.51082 -0.02656 0.53257 2.67596 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.65939 0.8120 ## wave 0.04979 0.2231 -0.35 ## Residual 0.49342 0.7024 ## Number of obs: 1304, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.54586 0.05441 340.07130 10.032 &lt; 2e-16 *** ## wave 0.11851 0.02133 331.21032 5.556 5.67e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## wave -0.545 sjPlot::tab_model(mlm.lmerTest, mlm.nlme, show.se = TRUE, show.df = FALSE, show.ci = FALSE, digits = 3, pred.labels = c(&#39;Intercept&#39;, &#39;Wave&#39;), dv.labels = c(&#39;lmer&#39;,&#39;nlme&#39;), string.se = &#39;SE&#39;, string.p = &#39;P-Value&#39;)   lmer nlme Predictors Estimates SE P-Value Estimates SE P-Value Intercept 0.546 0.054 &lt;0.001 0.546 0.054 &lt;0.001 Wave 0.119 0.021 &lt;0.001 0.119 0.021 &lt;0.001 Random Effects σ2 0.49 0.49 τ00 0.66 id 0.66 id τ11 0.05 id.wave 0.05 id.wave ρ01 -0.35 id -0.35 id ICC 0.57 0.57 N 342 id 342 id Observations 1304 1304 Marginal R2 / Conditional R2 0.015 / 0.572 0.015 / 0.572 ggplot2::ggplot(tidyr::drop_na(canonical.long), aes(x = wave + 1, y = predict(mlm.lmerTest), group = id, color = factor(id))) + geom_line() + labs(title = &#39;Canonical MLM Trajectories&#39;, x = &#39;Wave&#39;, y = &#39;Predicted DLFPC Activation&#39;) + theme(legend.position = &#39;none&#39;) Link to SAS &amp; Mplus code Generalized Additive Mixed Model gamm = gamm4::gamm4(modularity ~ s(age), random = ~ (1 | id), data = canonical.gamm) summary(gamm$mer) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## ## REML criterion at convergence: -18205.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.1619 -0.6701 -0.0474 0.6448 3.3380 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.0006274 0.02505 ## Xr s(age) 0.0024247 0.04924 ## Residual 0.0011387 0.03375 ## Number of obs: 4799, groups: id, 297; Xr, 8 ## ## Fixed effects: ## Estimate Std. Error t value ## X(Intercept) 0.137341 0.001541 89.10 ## Xs(age)Fx1 0.011550 0.006562 1.76 ## ## Correlation of Fixed Effects: ## X(Int) ## Xs(age)Fx1 -0.001 summary(gamm$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## modularity ~ s(age) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.137341 0.001541 89.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 5.733 5.733 39.75 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.0984 ## lmer.REML = -18205 Scale est. = 0.0011387 n = 4799 plot(gamm$gam) Latent Curve Model linear.lcm = &#39;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&#39; lcm = lavaan::growth(linear.lcm, data = canonical.wide, estimator = &#39;ML&#39;, missing=&#39;FIML&#39;) summary(lcm, fit.measures = TRUE, standardize = TRUE, rsquare = TRUE) lavaan 0.6-9 ended normally after 22 iterations Estimator ML Optimization method NLMINB Number of model parameters 9 Number of observations 342 Number of missing patterns 8 Model Test User Model: Test statistic 1.229 Degrees of freedom 5 P-value (Chi-square) 0.942 Model Test Baseline Model: Test statistic 381.370 Degrees of freedom 6 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 1.000 Tucker-Lewis Index (TLI) 1.012 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -1735.785 Loglikelihood unrestricted model (H1) -1735.170 Akaike (AIC) 3489.570 Bayesian (BIC) 3524.083 Sample-size adjusted Bayesian (BIC) 3495.533 Root Mean Square Error of Approximation: RMSEA 0.000 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.014 P-value RMSEA &lt;= 0.05 0.990 Standardized Root Mean Square Residual: SRMR 0.016 Parameter Estimates: Standard errors Standard Information Observed Observed information based on Hessian Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all int =~ dlpfc1 1.000 0.880 0.878 dlpfc2 1.000 0.880 0.813 dlpfc3 1.000 0.880 0.810 dlpfc4 1.000 0.880 0.820 slp =~ dlpfc1 0.000 0.000 0.000 dlpfc2 1.000 0.287 0.265 dlpfc3 2.000 0.574 0.528 dlpfc4 3.000 0.861 0.802 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all int ~~ slp -0.126 0.031 -4.102 0.000 -0.499 -0.499 Intercepts: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .dlpfc1 0.000 0.000 0.000 .dlpfc2 0.000 0.000 0.000 .dlpfc3 0.000 0.000 0.000 .dlpfc4 0.000 0.000 0.000 int 0.543 0.053 10.181 0.000 0.617 0.617 slp 0.121 0.021 5.705 0.000 0.420 0.420 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .dlpfc1 0.231 0.063 3.675 0.000 0.231 0.229 .dlpfc2 0.568 0.055 10.261 0.000 0.568 0.484 .dlpfc3 0.582 0.058 10.117 0.000 0.582 0.493 .dlpfc4 0.393 0.074 5.308 0.000 0.393 0.341 int 0.775 0.086 9.009 0.000 1.000 1.000 slp 0.082 0.016 5.180 0.000 1.000 1.000 R-Square: Estimate dlpfc1 0.771 dlpfc2 0.516 dlpfc3 0.507 dlpfc4 0.659 broom::tidy(lcm) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox int =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.8803856 0.8778670 0.8778670 int =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.8803856 0.8129018 0.8129018 int =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.8803856 0.8095689 0.8095689 int =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.8803856 0.8201402 0.8201402 slp =~ dlpfc1 =~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 slp =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.2869849 0.2649867 0.2649867 slp =~ dlpfc3 =~ 2.0000000 0.0000000 NA NA 0.5739697 0.5278006 0.5278006 slp =~ dlpfc4 =~ 3.0000000 0.0000000 NA NA 0.8609546 0.8020388 0.8020388 dlpfc1 ~~ dlpfc1 ~~ 0.2306675 0.0627685 3.674895 0.0002379 0.2306675 0.2293496 0.2293496 dlpfc2 ~~ dlpfc2 ~~ 0.5676883 0.0553225 10.261443 0.0000000 0.5676883 0.4839942 0.4839942 dlpfc3 ~~ dlpfc3 ~~ 0.5824885 0.0575772 10.116653 0.0000000 0.5824885 0.4925486 0.4925486 dlpfc4 ~~ dlpfc4 ~~ 0.3926006 0.0739665 5.307819 0.0000001 0.3926006 0.3407072 0.3407072 int ~~ int ~~ 0.7750788 0.0860379 9.008570 0.0000000 1.0000000 1.0000000 1.0000000 slp ~~ slp ~~ 0.0823603 0.0159001 5.179858 0.0000002 1.0000000 1.0000000 1.0000000 int ~~ slp ~~ -0.1261019 0.0307397 -4.102249 0.0000409 -0.4991024 -0.4991024 -0.4991024 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.5428063 0.0533134 10.181432 0.0000000 0.6165552 0.6165552 0.6165552 slp ~1 ~1 0.1205215 0.0211246 5.705278 0.0000000 0.4199578 0.4199578 0.4199578 semPlot::semPaths(lcm, intercepts = TRUE, edge.color = &#39;black&#39;) lcm = lavaan::growth(linear.lcm, data = drop_na(canonical.wide), estimator = &#39;ML&#39;, missing=&#39;FIML&#39;) summary(lcm, fit.measures = TRUE, standardize = TRUE, rsquare = TRUE) lavaan 0.6-9 ended normally after 23 iterations Estimator ML Optimization method NLMINB Number of model parameters 9 Number of observations 296 Number of missing patterns 1 Model Test User Model: Test statistic 0.860 Degrees of freedom 5 P-value (Chi-square) 0.973 Model Test Baseline Model: Test statistic 358.579 Degrees of freedom 6 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 1.000 Tucker-Lewis Index (TLI) 1.014 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -1553.921 Loglikelihood unrestricted model (H1) -1553.491 Akaike (AIC) 3125.843 Bayesian (BIC) 3159.056 Sample-size adjusted Bayesian (BIC) 3130.514 Root Mean Square Error of Approximation: RMSEA 0.000 90 Percent confidence interval - lower 0.000 90 Percent confidence interval - upper 0.000 P-value RMSEA &lt;= 0.05 0.995 Standardized Root Mean Square Residual: SRMR 0.013 Parameter Estimates: Standard errors Standard Information Observed Observed information based on Hessian Latent Variables: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all int =~ dlpfc1 1.000 0.873 0.883 dlpfc2 1.000 0.873 0.823 dlpfc3 1.000 0.873 0.817 dlpfc4 1.000 0.873 0.823 slp =~ dlpfc1 0.000 0.000 0.000 dlpfc2 1.000 0.285 0.269 dlpfc3 2.000 0.570 0.533 dlpfc4 3.000 0.856 0.807 Covariances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all int ~~ slp -0.128 0.031 -4.153 0.000 -0.512 -0.512 Intercepts: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .dlpfc1 0.000 0.000 0.000 .dlpfc2 0.000 0.000 0.000 .dlpfc3 0.000 0.000 0.000 .dlpfc4 0.000 0.000 0.000 int 0.554 0.057 9.799 0.000 0.634 0.634 slp 0.119 0.022 5.414 0.000 0.418 0.418 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .dlpfc1 0.216 0.062 3.483 0.000 0.216 0.221 .dlpfc2 0.537 0.054 9.889 0.000 0.537 0.477 .dlpfc3 0.566 0.058 9.821 0.000 0.566 0.495 .dlpfc4 0.396 0.074 5.372 0.000 0.396 0.352 int 0.762 0.088 8.618 0.000 1.000 1.000 slp 0.081 0.016 5.165 0.000 1.000 1.000 R-Square: Estimate dlpfc1 0.779 dlpfc2 0.523 dlpfc3 0.505 dlpfc4 0.648 broom::tidy(lcm) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox int =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.8730747 0.8826672 0.8826672 int =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.8730747 0.8229608 0.8229608 int =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.8730747 0.8166431 0.8166431 int =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.8730747 0.8230783 0.8230783 slp =~ dlpfc1 =~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 slp =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.2851767 0.2688078 0.2688078 slp =~ dlpfc3 =~ 2.0000000 0.0000000 NA NA 0.5703534 0.5334883 0.5334883 slp =~ dlpfc4 =~ 3.0000000 0.0000000 NA NA 0.8555300 0.8065384 0.8065384 dlpfc1 ~~ dlpfc1 ~~ 0.2161233 0.0620584 3.482582 0.0004966 0.2161233 0.2208986 0.2208986 dlpfc2 ~~ dlpfc2 ~~ 0.5370589 0.0543112 9.888545 0.0000000 0.5370589 0.4771748 0.4771748 dlpfc3 ~~ dlpfc3 ~~ 0.5657101 0.0576036 9.820738 0.0000000 0.5657101 0.4949436 0.4949436 dlpfc4 ~~ dlpfc4 ~~ 0.3964252 0.0738010 5.371545 0.0000001 0.3964252 0.3523228 0.3523228 int ~~ int ~~ 0.7622593 0.0884524 8.617731 0.0000000 1.0000000 1.0000000 1.0000000 slp ~~ slp ~~ 0.0813257 0.0157450 5.165171 0.0000002 1.0000000 1.0000000 1.0000000 int ~~ slp ~~ -0.1275734 0.0307199 -4.152799 0.0000328 -0.5123829 -0.5123829 -0.5123829 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.5537577 0.0565118 9.798972 0.0000000 0.6342616 0.6342616 0.6342616 slp ~1 ~1 0.1192957 0.0220347 5.413982 0.0000001 0.4183221 0.4183221 0.4183221 ggplot2::ggplot(data.frame(id=lcm@Data@case.idx[[1]], lavPredict(lcm,type=&#39;ov&#39;)) %&gt;% pivot_longer(cols = starts_with(&#39;dlpfc&#39;), names_to = c(&#39;.value&#39;, &#39;wave&#39;), names_pattern = &#39;(.+)(.)&#39;) %&gt;% dplyr::mutate(wave = as.numeric(wave)), aes(x = wave, y = dlpfc, group = id, color = factor(id))) + geom_line() + labs(title = &#39;Canonical LCM Trajectories&#39;, x = &#39;Wave&#39;, y = &#39;Predicted DLFPC Activation&#39;) + theme(legend.position = &#39;none&#39;) Link to Mplus code Latent Change Score Model linear.lcsm = &#39; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &#39; lcsm.linear = sem(linear.lcsm, data = canonical.wide, estimator = &#39;ML&#39;, missing = &#39;FIML&#39;) summary(lcsm.linear, fit.measures = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.229 ## Degrees of freedom 5 ## P-value (Chi-square) 0.942 ## ## Model Test Baseline Model: ## ## Test statistic 381.370 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.012 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 ## Loglikelihood unrestricted model (H1) -1735.170 ## ## Akaike (AIC) 3489.570 ## Bayesian (BIC) 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.014 ## P-value RMSEA &lt;= 0.05 0.990 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pdlpfc1 =~ ## dlpfc1 1.000 0.880 0.878 ## pdlpfc2 =~ ## dlpfc2 1.000 0.778 0.718 ## pdlpfc3 =~ ## dlpfc3 1.000 0.775 0.712 ## pdlpfc4 =~ ## dlpfc4 1.000 0.872 0.812 ## delta21 =~ ## pdlpfc2 1.000 0.369 0.369 ## delta32 =~ ## pdlpfc3 1.000 0.370 0.370 ## delta43 =~ ## pdlpfc4 1.000 0.329 0.329 ## int =~ ## pdlpfc1 1.000 1.000 1.000 ## slp =~ ## delta21 1.000 1.000 1.000 ## delta32 1.000 1.000 1.000 ## delta43 1.000 1.000 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pdlpfc2 ~ ## pdlpfc1 1.000 1.132 1.132 ## pdlpfc3 ~ ## pdlpfc2 1.000 1.004 1.004 ## pdlpfc4 ~ ## pdlpfc3 1.000 0.889 0.889 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.126 0.031 -4.102 0.000 -0.499 -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.000 0.000 0.000 ## int 0.543 0.053 10.181 0.000 0.617 0.617 ## slp 0.121 0.021 5.705 0.000 0.420 0.420 ## .pdlpfc1 0.000 0.000 0.000 ## .pdlpfc2 0.000 0.000 0.000 ## .pdlpfc3 0.000 0.000 0.000 ## .pdlpfc4 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.231 0.063 3.675 0.000 0.231 0.229 ## .pdlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.568 0.055 10.261 0.000 0.568 0.484 ## .pdlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.582 0.058 10.117 0.000 0.582 0.493 ## .pdlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.393 0.074 5.308 0.000 0.393 0.341 ## .pdlpfc4 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## slp 0.082 0.016 5.180 0.000 1.000 1.000 ## int 0.775 0.086 9.009 0.000 1.000 1.000 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## pdlpfc1 1.000 ## dlpfc2 0.516 ## pdlpfc2 1.000 ## dlpfc3 0.507 ## pdlpfc3 1.000 ## dlpfc4 0.659 ## pdlpfc4 1.000 ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 broom::tidy(lcsm.linear) %&gt;% arrange(op) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox pdlpfc1 =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.8803856 0.8778670 0.8778670 pdlpfc2 =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.7779687 0.7183354 0.7183354 pdlpfc3 =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.7746693 0.7123562 0.7123562 pdlpfc4 =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.8716136 0.8119685 0.8119685 delta21 =~ pdlpfc2 =~ 1.0000000 0.0000000 NA NA 0.3688900 0.3688900 0.3688900 delta32 =~ pdlpfc3 =~ 1.0000000 0.0000000 NA NA 0.3704611 0.3704611 0.3704611 delta43 =~ pdlpfc4 =~ 1.0000000 0.0000000 NA NA 0.3292570 0.3292570 0.3292570 int =~ pdlpfc1 =~ 1.0000000 0.0000000 NA NA 1.0000000 1.0000000 1.0000000 slp =~ delta21 =~ 1.0000000 0.0000000 NA NA 1.0000000 1.0000000 1.0000000 slp =~ delta32 =~ 1.0000000 0.0000000 NA NA 1.0000000 1.0000000 1.0000000 slp =~ delta43 =~ 1.0000000 0.0000000 NA NA 1.0000000 1.0000000 1.0000000 pdlpfc2 ~ pdlpfc1 ~ 1.0000000 0.0000000 NA NA 1.1316465 1.1316465 1.1316465 pdlpfc3 ~ pdlpfc2 ~ 1.0000000 0.0000000 NA NA 1.0042592 1.0042592 1.0042592 pdlpfc4 ~ pdlpfc3 ~ 1.0000000 0.0000000 NA NA 0.8887760 0.8887760 0.8887760 dlpfc1 ~~ dlpfc1 ~~ 0.2306675 0.0627685 3.674895 0.0002379 0.2306675 0.2293496 0.2293496 pdlpfc1 ~~ pdlpfc1 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~~ dlpfc2 ~~ 0.5676883 0.0553225 10.261443 0.0000000 0.5676883 0.4839942 0.4839942 pdlpfc2 ~~ pdlpfc2 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~~ dlpfc3 ~~ 0.5824885 0.0575772 10.116653 0.0000000 0.5824885 0.4925486 0.4925486 pdlpfc3 ~~ pdlpfc3 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~~ dlpfc4 ~~ 0.3926006 0.0739665 5.307819 0.0000001 0.3926006 0.3407072 0.3407072 pdlpfc4 ~~ pdlpfc4 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta21 ~~ delta21 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta32 ~~ delta32 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta43 ~~ delta43 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~~ slp ~~ -0.1261019 0.0307397 -4.102249 0.0000409 -0.4991024 -0.4991024 -0.4991024 slp ~~ slp ~~ 0.0823603 0.0159001 5.179858 0.0000002 1.0000000 1.0000000 1.0000000 int ~~ int ~~ 0.7750788 0.0860379 9.008570 0.0000000 1.0000000 1.0000000 1.0000000 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.5428063 0.0533134 10.181432 0.0000000 0.6165552 0.6165552 0.6165552 slp ~1 ~1 0.1205215 0.0211246 5.705278 0.0000000 0.4199578 0.4199578 0.4199578 pdlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 pdlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 pdlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 pdlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta21 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta32 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta43 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 semPlot::semPaths(lcsm.linear, layout = &#39;tree2&#39;, intercepts = FALSE, edge.color = &#39;black&#39;) proportional.lcsm = &#39; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Proportional Change Regressions (beta = equality constraint) delta21 ~ beta*pdlpfc1 delta32 ~ beta*pdlpfc2 delta43 ~ beta*pdlpfc3 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &#39; lcsm.proportional = sem(proportional.lcsm, data = canonical.wide, estimator = &#39;ML&#39;, missing = &#39;FIML&#39;) summary(lcsm.proportional, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 32 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## Number of equality constraints 2 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.132 ## Degrees of freedom 4 ## P-value (Chi-square) 0.889 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pdlpfc1 =~ ## dlpfc1 1.000 0.892 0.891 ## pdlpfc2 =~ ## dlpfc2 1.000 0.777 0.716 ## pdlpfc3 =~ ## dlpfc3 1.000 0.776 0.714 ## pdlpfc4 =~ ## dlpfc4 1.000 0.861 0.802 ## delta21 =~ ## pdlpfc2 1.000 0.405 0.405 ## delta32 =~ ## pdlpfc3 1.000 0.370 0.370 ## delta43 =~ ## pdlpfc4 1.000 0.303 0.303 ## int =~ ## pdlpfc1 1.000 1.000 1.000 ## slp =~ ## delta21 1.000 0.895 0.895 ## delta32 1.000 0.983 0.983 ## delta43 1.000 1.080 1.080 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pdlpfc2 ~ ## pdlpfc1 1.000 1.148 1.148 ## pdlpfc3 ~ ## pdlpfc2 1.000 1.002 1.002 ## pdlpfc4 ~ ## pdlpfc3 1.000 0.900 0.900 ## delta21 ~ ## pdlpfc1 (beta) -0.090 0.276 -0.325 0.745 -0.254 -0.254 ## delta32 ~ ## pdlpfc2 (beta) -0.090 0.276 -0.325 0.745 -0.243 -0.243 ## delta43 ~ ## pdlpfc3 (beta) -0.090 0.276 -0.325 0.745 -0.267 -0.267 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.074 0.162 -0.457 0.647 -0.295 -0.295 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.000 0.000 0.000 ## int 0.540 0.054 9.994 0.000 0.605 0.605 ## slp 0.179 0.183 0.981 0.326 0.637 0.637 ## .pdlpfc1 0.000 0.000 0.000 ## .pdlpfc2 0.000 0.000 0.000 ## .pdlpfc3 0.000 0.000 0.000 ## .pdlpfc4 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.208 0.102 2.043 0.041 0.208 0.207 ## .pdlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.573 0.058 9.820 0.000 0.573 0.487 ## .pdlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.577 0.060 9.570 0.000 0.577 0.490 ## .pdlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.413 0.095 4.358 0.000 0.413 0.357 ## .pdlpfc4 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## slp 0.079 0.016 4.970 0.000 1.000 1.000 ## int 0.796 0.115 6.925 0.000 1.000 1.000 ## ## R-Square: ## Estimate ## dlpfc1 0.793 ## pdlpfc1 1.000 ## dlpfc2 0.513 ## pdlpfc2 1.000 ## dlpfc3 0.510 ## pdlpfc3 1.000 ## dlpfc4 0.643 ## pdlpfc4 1.000 ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 broom::tidy(lcsm.proportional) %&gt;% arrange(op) %&gt;% knitr::kable() term op label estimate std.error statistic p.value std.lv std.all std.nox pdlpfc1 =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.8923116 0.8905217 0.8905217 pdlpfc2 =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.7772019 0.7163396 0.7163396 pdlpfc3 =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.7755836 0.7144729 0.7144729 pdlpfc4 =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.8614512 0.8016474 0.8016474 delta21 =~ pdlpfc2 =~ 1.0000000 0.0000000 NA NA 0.4051634 0.4051634 0.4051634 delta32 =~ pdlpfc3 =~ 1.0000000 0.0000000 NA NA 0.3695688 0.3695688 0.3695688 delta43 =~ pdlpfc4 =~ 1.0000000 0.0000000 NA NA 0.3028677 0.3028677 0.3028677 int =~ pdlpfc1 =~ 1.0000000 0.0000000 NA NA 1.0000000 1.0000000 1.0000000 slp =~ delta21 =~ 1.0000000 0.0000000 NA NA 0.8949773 0.8949773 0.8949773 slp =~ delta32 =~ 1.0000000 0.0000000 NA NA 0.9832234 0.9832234 0.9832234 slp =~ delta43 =~ 1.0000000 0.0000000 NA NA 1.0801707 1.0801707 1.0801707 pdlpfc2 ~ pdlpfc1 ~ 1.0000000 0.0000000 NA NA 1.1481079 1.1481079 1.1481079 pdlpfc3 ~ pdlpfc2 ~ 1.0000000 0.0000000 NA NA 1.0020866 1.0020866 1.0020866 pdlpfc4 ~ pdlpfc3 ~ 1.0000000 0.0000000 NA NA 0.9003221 0.9003221 0.9003221 delta21 ~ pdlpfc1 ~ beta -0.0897518 0.2764440 -0.3246654 0.7454343 -0.2543289 -0.2543289 -0.2543289 delta32 ~ pdlpfc2 ~ beta -0.0897518 0.2764440 -0.3246654 0.7454343 -0.2433622 -0.2433622 -0.2433622 delta43 ~ pdlpfc3 ~ beta -0.0897518 0.2764440 -0.3246654 0.7454343 -0.2668014 -0.2668014 -0.2668014 dlpfc1 ~~ dlpfc1 ~~ 0.2078039 0.1017277 2.0427461 0.0410776 0.2078039 0.2069711 0.2069711 pdlpfc1 ~~ pdlpfc1 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~~ dlpfc2 ~~ 0.5731018 0.0583595 9.8201933 0.0000000 0.5731018 0.4868576 0.4868576 pdlpfc2 ~~ pdlpfc2 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~~ dlpfc3 ~~ 0.5768512 0.0602754 9.5702617 0.0000000 0.5768512 0.4895285 0.4895285 pdlpfc3 ~~ pdlpfc3 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~~ dlpfc4 ~~ 0.4126695 0.0946892 4.3581487 0.0000131 0.4126695 0.3573615 0.3573615 pdlpfc4 ~~ pdlpfc4 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta21 ~~ delta21 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta32 ~~ delta32 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta43 ~~ delta43 ~~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~~ slp ~~ -0.0742055 0.1622352 -0.4573943 0.6473877 -0.2950824 -0.2950824 -0.2950824 slp ~~ slp ~~ 0.0794241 0.0159809 4.9699267 0.0000007 1.0000000 1.0000000 1.0000000 int ~~ int ~~ 0.7962200 0.1149780 6.9249748 0.0000000 1.0000000 1.0000000 1.0000000 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.5400618 0.0540377 9.9941688 0.0000000 0.6052390 0.6052390 0.6052390 slp ~1 ~1 0.1794875 0.1828966 0.9813606 0.3264150 0.6368806 0.6368806 0.6368806 pdlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 pdlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 pdlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 pdlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta21 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta32 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 delta43 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 semPlot::semPaths(lcsm.proportional, layout = &#39;tree2&#39;, intercepts = FALSE, edge.color = &#39;black&#39;) ggplot2::ggplot(data.frame(id=lcsm.proportional@Data@case.idx[[1]], lavPredict(lcsm.proportional,type=&#39;ov&#39;)) %&gt;% pivot_longer(cols = starts_with(&#39;dlpfc&#39;), names_to = c(&#39;.value&#39;, &#39;wave&#39;), names_pattern = &#39;(.+)(.)&#39;) %&gt;% dplyr::mutate(wave = as.numeric(wave)), aes(x = wave, y = dlpfc, group = id, color = factor(id))) + geom_line() + labs(title = &#39;Canonical Proportional LCSM Trajectories&#39;, x = &#39;Wave&#39;, y = &#39;Predicted DLFPC Activation&#39;) + theme(legend.position = &#39;none&#39;) Link to mplus code "],["03-time.html", "Time Structure Assessment Schedules Time Coding Additional Considerations", " Time Structure Thinking more deeply about time in longitudinal models single.cohort = read.csv(&#39;data/02-single-cohort.csv&#39;) multiple.cohort = read.csv(&#39;data/02-multiple-cohort.csv&#39;) accelerated = read.csv(&#39;data/02-accelerated.csv&#39;) Assessment Schedules Single Cohort Data set.seed(12345) ggplot2::ggplot(single.cohort %&gt;% filter(id %in% sample(id, 50)) %&gt;% pivot_longer(cols=starts_with(&#39;age&#39;), names_to = c(&#39;.value&#39;, &#39;wave&#39;), names_pattern = &#39;(.+)(.)&#39;), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &#39;Age&#39;, y = &#39;Individual&#39;, color = &#39;Wave&#39;) + theme(legend.position = &#39;top&#39;) linear.lcm = &#39;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&#39; lcm = lavaan::growth(linear.lcm, data = single.cohort, estimator = &#39;ML&#39;, missing=&#39;FIML&#39;) summary(lcm, fit.measures = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## dlpfc1 1.000 0.794 0.832 ## dlpfc2 1.000 0.794 0.773 ## dlpfc3 1.000 0.794 0.772 ## dlpfc4 1.000 0.794 0.650 ## slp =~ ## dlpfc1 0.000 0.000 0.000 ## dlpfc2 1.000 0.234 0.228 ## dlpfc3 2.000 0.468 0.455 ## dlpfc4 3.000 0.703 0.575 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.045 0.097 -0.467 0.641 -0.243 -0.243 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.000 0.000 0.000 ## int 0.628 0.132 4.761 0.000 0.791 0.791 ## slp 0.114 0.054 2.120 0.034 0.487 0.487 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.280 0.196 1.427 0.154 0.280 0.307 ## .dlpfc2 0.459 0.140 3.275 0.001 0.459 0.435 ## .dlpfc3 0.389 0.128 3.039 0.002 0.389 0.368 ## .dlpfc4 0.640 0.278 2.302 0.021 0.640 0.428 ## int 0.631 0.207 3.039 0.002 1.000 1.000 ## slp 0.055 0.054 1.010 0.313 1.000 1.000 ## ## R-Square: ## Estimate ## dlpfc1 0.693 ## dlpfc2 0.565 ## dlpfc3 0.632 ## dlpfc4 0.572 broom::tidy(lcm) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox int =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.8323286 0.8323286 int =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.7734266 0.7734266 int =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.7718441 0.7718441 int =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.6498139 0.6498139 slp =~ dlpfc1 =~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 slp =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.2342260 0.2281451 0.2281451 slp =~ dlpfc3 =~ 2.0000000 0.0000000 NA NA 0.4684521 0.4553567 0.4553567 slp =~ dlpfc4 =~ 3.0000000 0.0000000 NA NA 0.7026781 0.5750458 0.5750458 dlpfc1 ~~ dlpfc1 ~~ 0.2796138 0.1959794 1.4267507 0.1536518 0.2796138 0.3072290 0.3072290 dlpfc2 ~~ dlpfc2 ~~ 0.4589404 0.1401353 3.2749802 0.0010567 0.4589404 0.4354200 0.4354200 dlpfc3 ~~ dlpfc3 ~~ 0.3889671 0.1280032 3.0387293 0.0023758 0.3889671 0.3675243 0.3675243 dlpfc4 ~~ dlpfc4 ~~ 0.6397657 0.2778724 2.3023728 0.0213142 0.6397657 0.4284626 0.4284626 int ~~ int ~~ 0.6305014 0.2074521 3.0392633 0.0023716 1.0000000 1.0000000 1.0000000 slp ~~ slp ~~ 0.0548618 0.0543242 1.0098967 0.3125448 1.0000000 1.0000000 1.0000000 int ~~ slp ~~ -0.0451430 0.0967540 -0.4665746 0.6408043 -0.2427236 -0.2427236 -0.2427236 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.6284401 0.1320054 4.7607134 0.0000019 0.7914452 0.7914452 0.7914452 slp ~1 ~1 0.1139803 0.0537695 2.1197937 0.0340234 0.4866253 0.4866253 0.4866253 semPlot::semPaths(lcm, intercepts = TRUE, edge.color = &#39;black&#39;) Notes: not sure we need to re-show all the models since all the canonical ones are on single-cohort data Multiple Cohort Data ggplot(multiple.cohort %&gt;% filter(id %in% sample(id, 50)) %&gt;% pivot_longer(cols=starts_with(&#39;monthage&#39;), names_to = c(&#39;.value&#39;, &#39;wave&#39;), names_pattern = &#39;(.+)(.)&#39;), aes(x = monthage, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave), shape = factor(cohort)), size=2) + labs(x = &#39;Age (in Months)&#39;, y = &#39;Individual&#39;, color = &#39;Wave&#39;, shape = &#39;Cohort&#39;) + theme(legend.position = &#39;top&#39;) + guides(color = &#39;none&#39;) ## Warning: Removed 246 row(s) containing missing values (geom_path). ## Warning: Removed 246 rows containing missing values (geom_point). linear.lcm = &#39;int =~ 1*fpct6 + 1*fpct8 + 1*fpct10 + 1*fpct12 + 1*fpct14 + 1*fpct16 + 1*fpct18 + 1*fpct20 slp =~ 0*fpct6 + 1*fpct8 + 2*fpct10 + 3*fpct12 + 4*fpct14 + 5*fpct16 + 6*fpct18 + 7*fpct20&#39; lcm = lavaan::growth(linear.lcm, data = multiple.cohort, estimator = &#39;ML&#39;, missing=&#39;FIML&#39;) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : lavaan WARNING: due to ## missing values, some pairwise combinations have less than 10% coverage ## Warning in lav_mvnorm_missing_h1_estimate_moments(Y = X[[g]], wt = WT[[g]], : lavaan WARNING: ## Maximum number of iterations reached when computing the sample ## moments using EM; use the em.h1.iter.max= argument to increase the ## number of iterations summary(lcm, fit.measures = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 51 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 405 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 43.254 ## Degrees of freedom 31 ## P-value (Chi-square) 0.071 ## ## Model Test Baseline Model: ## ## Test statistic 331.344 ## Degrees of freedom 28 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.960 ## Tucker-Lewis Index (TLI) 0.964 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2442.146 ## Loglikelihood unrestricted model (H1) -2420.520 ## ## Akaike (AIC) 4910.293 ## Bayesian (BIC) 4962.343 ## Sample-size adjusted Bayesian (BIC) 4921.093 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.031 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.052 ## P-value RMSEA &lt;= 0.05 0.931 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fpct6 1.000 1.085 0.636 ## fpct8 1.000 1.085 0.682 ## fpct10 1.000 1.085 0.620 ## fpct12 1.000 1.085 0.578 ## fpct14 1.000 1.085 0.532 ## fpct16 1.000 1.085 0.534 ## fpct18 1.000 1.085 0.541 ## fpct20 1.000 1.085 0.479 ## slp =~ ## fpct6 0.000 0.000 0.000 ## fpct8 1.000 0.204 0.129 ## fpct10 2.000 0.409 0.234 ## fpct12 3.000 0.613 0.327 ## fpct14 4.000 0.818 0.401 ## fpct16 5.000 1.022 0.503 ## fpct18 6.000 1.227 0.612 ## fpct20 7.000 1.431 0.632 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 0.020 0.063 0.312 0.755 0.088 0.088 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fpct6 0.000 0.000 0.000 ## .fpct8 0.000 0.000 0.000 ## .fpct10 0.000 0.000 0.000 ## .fpct12 0.000 0.000 0.000 ## .fpct14 0.000 0.000 0.000 ## .fpct16 0.000 0.000 0.000 ## .fpct18 0.000 0.000 0.000 ## .fpct20 0.000 0.000 0.000 ## int 1.600 0.087 18.329 0.000 1.475 1.475 ## slp 0.083 0.020 4.144 0.000 0.406 0.406 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fpct6 1.737 0.386 4.499 0.000 1.737 0.596 ## .fpct8 1.271 0.282 4.512 0.000 1.271 0.503 ## .fpct10 1.639 0.286 5.726 0.000 1.639 0.535 ## .fpct12 1.854 0.250 7.406 0.000 1.854 0.526 ## .fpct14 2.162 0.336 6.427 0.000 2.162 0.519 ## .fpct16 1.709 0.258 6.612 0.000 1.709 0.414 ## .fpct18 1.106 0.316 3.498 0.000 1.106 0.275 ## .fpct20 1.623 0.343 4.730 0.000 1.623 0.317 ## int 1.177 0.320 3.680 0.000 1.000 1.000 ## slp 0.042 0.016 2.645 0.008 1.000 1.000 ## ## R-Square: ## Estimate ## fpct6 0.404 ## fpct8 0.497 ## fpct10 0.465 ## fpct12 0.474 ## fpct14 0.481 ## fpct16 0.586 ## fpct18 0.725 ## fpct20 0.683 broom::tidy(lcm) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox int =~ fpct6 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.6355140 0.6355140 int =~ fpct8 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.6822177 0.6822177 int =~ fpct10 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.6199778 0.6199778 int =~ fpct12 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.5778669 0.5778669 int =~ fpct14 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.5315924 0.5315924 int =~ fpct16 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.5340599 0.5340599 int =~ fpct18 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.5409223 0.5409223 int =~ fpct20 =~ 1.0000000 0.0000000 NA NA 1.0848449 0.4793595 0.4793595 slp =~ fpct6 =~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 slp =~ fpct8 =~ 1.0000000 0.0000000 NA NA 0.2044304 0.1285585 0.1285585 slp =~ fpct10 =~ 2.0000000 0.0000000 NA NA 0.4088608 0.2336598 0.2336598 slp =~ fpct12 =~ 3.0000000 0.0000000 NA NA 0.6132912 0.3266832 0.3266832 slp =~ fpct14 =~ 4.0000000 0.0000000 NA NA 0.8177216 0.4006974 0.4006974 slp =~ fpct16 =~ 5.0000000 0.0000000 NA NA 1.0221520 0.5031967 0.5031967 slp =~ fpct18 =~ 6.0000000 0.0000000 NA NA 1.2265824 0.6115950 0.6115950 slp =~ fpct20 =~ 7.0000000 0.0000000 NA NA 1.4310128 0.6323204 0.6323204 fpct6 ~~ fpct6 ~~ 1.7370816 0.3861237 4.4987702 0.0000068 1.7370816 0.5961220 0.5961220 fpct8 ~~ fpct8 ~~ 1.2708063 0.2816246 4.5124120 0.0000064 1.2708063 0.5025624 0.5025624 fpct10 ~~ fpct10 ~~ 1.6394538 0.2863074 5.7262019 0.0000000 1.6394538 0.5354466 0.5354466 fpct12 ~~ fpct12 ~~ 1.8538399 0.2503021 7.4064107 0.0000000 1.8538399 0.5260081 0.5260081 fpct14 ~~ fpct14 ~~ 2.1624173 0.3364727 6.4267245 0.0000000 2.1624173 0.5192323 0.5192323 fpct16 ~~ fpct16 ~~ 1.7087292 0.2584130 6.6123962 0.0000000 1.7087292 0.4141121 0.4141121 fpct18 ~~ fpct18 ~~ 1.1058222 0.3160874 3.4984692 0.0004679 1.1058222 0.2749285 0.2749285 fpct20 ~~ fpct20 ~~ 1.6228270 0.3430886 4.7300515 0.0000022 1.6228270 0.3168542 0.3168542 int ~~ int ~~ 1.1768886 0.3198135 3.6799212 0.0002333 1.0000000 1.0000000 1.0000000 slp ~~ slp ~~ 0.0417918 0.0157976 2.6454494 0.0081582 1.0000000 1.0000000 1.0000000 int ~~ slp ~~ 0.0195836 0.0628649 0.3115183 0.7554067 0.0883037 0.0883037 0.0883037 fpct6 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct8 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct10 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct12 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct14 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct16 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct18 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 fpct20 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 1.5998873 0.0872869 18.3290572 0.0000000 1.4747613 1.4747613 1.4747613 slp ~1 ~1 0.0830330 0.0200355 4.1442873 0.0000341 0.4061674 0.4061674 0.4061674 semPlot::semPaths(lcm, intercepts = TRUE, edge.color = &#39;black&#39;) show with LCM since they are the most straightforward. Accelerated Design set.seed(12345) ggplot(accelerated %&gt;% group_by(id) %&gt;% filter(length(unique(wave)) == 3) %&gt;% ungroup() %&gt;% filter(id %in% sample(id, 100)), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &#39;Age&#39;, y = &#39;Individual&#39;, color = &#39;Wave&#39;, shape = &#39;Cohort&#39;) + theme(legend.position = &#39;top&#39;) mlm.lmerTest = lmerTest::lmer(scale(modularity) ~ 1 + age + I(age^2) + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) summary(mlm.lmerTest) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: scale(modularity) ~ 1 + age + I(age^2) + (1 | id) ## Data: accelerated ## ## REML criterion at convergence: 11850.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.2572 -0.6677 -0.0478 0.6411 3.3902 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.3276 0.5724 ## Residual 0.5990 0.7740 ## Number of obs: 4799, groups: id, 297 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -3.293e+00 2.445e-01 3.587e+03 -13.47 &lt;2e-16 *** ## age 3.633e-01 2.957e-02 3.761e+03 12.29 &lt;2e-16 *** ## I(age^2) -9.271e-03 8.806e-04 3.524e+03 -10.53 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.972 ## I(age^2) 0.917 -0.981 tab_model(mlm.lmerTest, show.se = TRUE, show.df = FALSE, show.ci = FALSE, digits = 3, pred.labels = c(&#39;Intercept&#39;, &#39;Age&#39;, &#39;Age^2&#39;), dv.labels = &#39;Modularity&#39;, string.se = &#39;SE&#39;, string.p = &#39;P-Value&#39;) ## Argument &#39;df_method&#39; is deprecated. Please use &#39;ci_method&#39; instead.   Modularity Predictors Estimates SE P-Value Intercept -3.293 0.244 &lt;0.001 Age 0.363 0.030 &lt;0.001 Age^2 -0.009 0.001 &lt;0.001 Random Effects σ2 0.60 τ00 id 0.33 ICC 0.35 N id 297 Observations 4799 Marginal R2 / Conditional R2 0.075 / 0.402 show with MLM/GAMM, link to Mplus code for the tscore method Time Coding initial.status = &#39;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&#39; initial.status.fit = growth(initial.status, data = single.cohort, estimator = &#39;ML&#39;, missing=&#39;FIML&#39;) final.status = &#39;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&#39; final.status.fit = growth(final.status, data = single.cohort, estimator = &#39;ML&#39;, missing=&#39;FIML&#39;) summary(initial.status.fit, fit.measures = TRUE, estimates=FALSE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 summary(final.status.fit, fit.measures = TRUE, estimates=FALSE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 tidy(initial.status.fit) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox int =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.8323286 0.8323286 int =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.7734266 0.7734266 int =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.7718441 0.7718441 int =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.6498139 0.6498139 slp =~ dlpfc1 =~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 slp =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.2342260 0.2281451 0.2281451 slp =~ dlpfc3 =~ 2.0000000 0.0000000 NA NA 0.4684521 0.4553567 0.4553567 slp =~ dlpfc4 =~ 3.0000000 0.0000000 NA NA 0.7026781 0.5750458 0.5750458 dlpfc1 ~~ dlpfc1 ~~ 0.2796138 0.1959794 1.4267507 0.1536518 0.2796138 0.3072290 0.3072290 dlpfc2 ~~ dlpfc2 ~~ 0.4589404 0.1401353 3.2749802 0.0010567 0.4589404 0.4354200 0.4354200 dlpfc3 ~~ dlpfc3 ~~ 0.3889671 0.1280032 3.0387293 0.0023758 0.3889671 0.3675243 0.3675243 dlpfc4 ~~ dlpfc4 ~~ 0.6397657 0.2778724 2.3023728 0.0213142 0.6397657 0.4284626 0.4284626 int ~~ int ~~ 0.6305014 0.2074521 3.0392633 0.0023716 1.0000000 1.0000000 1.0000000 slp ~~ slp ~~ 0.0548618 0.0543242 1.0098967 0.3125448 1.0000000 1.0000000 1.0000000 int ~~ slp ~~ -0.0451430 0.0967540 -0.4665746 0.6408043 -0.2427236 -0.2427236 -0.2427236 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.6284401 0.1320054 4.7607134 0.0000019 0.7914452 0.7914452 0.7914452 slp ~1 ~1 0.1139803 0.0537695 2.1197937 0.0340234 0.4866253 0.4866253 0.4866253 tidy(final.status.fit) %&gt;% knitr::kable() term op estimate std.error statistic p.value std.lv std.all std.nox int =~ dlpfc1 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.8323286 0.8323286 int =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.7734266 0.7734266 int =~ dlpfc3 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.7718441 0.7718441 int =~ dlpfc4 =~ 1.0000000 0.0000000 NA NA 0.7940412 0.6498139 0.6498139 slp =~ dlpfc1 =~ 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 slp =~ dlpfc2 =~ 1.0000000 0.0000000 NA NA 0.2342260 0.2281451 0.2281451 slp =~ dlpfc3 =~ 2.0000000 0.0000000 NA NA 0.4684521 0.4553567 0.4553567 slp =~ dlpfc4 =~ 3.0000000 0.0000000 NA NA 0.7026781 0.5750458 0.5750458 dlpfc1 ~~ dlpfc1 ~~ 0.2796138 0.1959794 1.4267507 0.1536518 0.2796138 0.3072290 0.3072290 dlpfc2 ~~ dlpfc2 ~~ 0.4589404 0.1401353 3.2749802 0.0010567 0.4589404 0.4354200 0.4354200 dlpfc3 ~~ dlpfc3 ~~ 0.3889671 0.1280032 3.0387293 0.0023758 0.3889671 0.3675243 0.3675243 dlpfc4 ~~ dlpfc4 ~~ 0.6397657 0.2778724 2.3023728 0.0213142 0.6397657 0.4284626 0.4284626 int ~~ int ~~ 0.6305014 0.2074521 3.0392633 0.0023716 1.0000000 1.0000000 1.0000000 slp ~~ slp ~~ 0.0548618 0.0543242 1.0098967 0.3125448 1.0000000 1.0000000 1.0000000 int ~~ slp ~~ -0.0451430 0.0967540 -0.4665746 0.6408043 -0.2427236 -0.2427236 -0.2427236 dlpfc1 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc2 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc3 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 dlpfc4 ~1 ~1 0.0000000 0.0000000 NA NA 0.0000000 0.0000000 0.0000000 int ~1 ~1 0.6284401 0.1320054 4.7607134 0.0000019 0.7914452 0.7914452 0.7914452 slp ~1 ~1 0.1139803 0.0537695 2.1197937 0.0340234 0.4866253 0.4866253 0.4866253 Show in the LCM since that’s the easiest to see in the model syntax, also highlight in the MLM Additional Considerations Alternative Metrics of Time ggplot(accelerated, aes(x = puberty, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &#39;Age&#39;, y = &#39;Individual&#39;, color = &#39;Wave&#39;, shape = &#39;Cohort&#39;) + theme(legend.position = &#39;top&#39;) ## Warning: Removed 1283 row(s) containing missing values (geom_path). ## Warning: Removed 1283 rows containing missing values (geom_point). Show data with puberty as the x variable Residual Estimates Show LCM and MLM specifications of both homo- and heteroscedastic "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
