[["index.html", "The Hitchhiker’s Guide to Longitudinal Models Code Companion About", " The Hitchhiker’s Guide to Longitudinal Models Code Companion Ethan M. McCormick, Michelle L. Byrne, John C. Flournoy, Katheryn L. Mills, &amp; Jennifer H. Pfiefer Published: 12 January, 2022 About The following document is a code companion to The Hitchhiker’s Guide to Longitudinal Models: A Primer on Model Selection for Repeated-Measures Methods, https://osf.io/bn6yu/. Some general notes about this code companion: We believe in the importance of using real data in our examples of longitudinal models. However, some of the models we discuss can not yet be fit using publicly-available neuroimaging data (most often due to a limited number of observations). To bridge this gap, we have synthesized data from a number of sources, detailed in Datasets. Variable names and identification codes have been changed to protect the innocent and to provide examples that will be familiar to developmental cognitive neuroscience researchers. However, one limitation of synthesized data is that model fits are often significantly worsened compared to the real data. As such, for pedagogical purposes, we will fit (and sometimes interpret) results from models that we would usually reject in practice based on overall model fit. Given the nature of R, there are likely several ways to accomplish what we outline here. This code should not be taken as the definitive one way that data manipulation or model fitting can be accomplished, but rather as a standard pipeline that should hopefully be accessible to new users of R and longitudinal methods more generally. In general, we will include the code used to generate the results. However, in the interest of spending more time on the models and associated syntax, we may not include an in-depth explanation of every function or syntax option. The rmarkdown source files are available in a public github repository for those interested. While the contents of this primer and code companion will focus on implementation in the R environment, links will be provided to other programs where possible. A fair warning: code in other languages will be provided in an arbitrary and capricious manner. This policy should be familiar to the reader, given their experience with the text of the manuscript (and if very unlucky, the first author). In general, precision beyond the third decimal place is as real as unicorns and so we will round our numbers to that level when discussing them. "],["01-introduction.html", "Introduction", " Introduction The first thing we can do is run a function that will load the R packages needed for this code companion, and install them to our machine if they are not already. packages &lt;- c(&quot;utils&quot;, &quot;tidyverse&quot;, &quot;downloadthis&quot;, # packages for data management &quot;foreign&quot;, &quot;MplusAutomation&quot;, # packages for writing data &quot;sjPlot&quot;, &quot;broom&quot;, &quot;kableExtra&quot;, # packages for generating tables &quot;nlme&quot;, &quot;lme4&quot;, &quot;lmerTest&quot;, # packages for MLMs &quot;mgcv&quot;, &quot;gamm4&quot;, &quot;itsadug&quot;, # packages for GAMMs &quot;lavaan&quot;, # packages for SEMs &quot;ggplot2&quot;, &quot;semPlot&quot;, &quot;ggeffects&quot;, # packages for visualization &quot;interactions&quot;) if (length(setdiff(packages, rownames(installed.packages()))) &gt; 0) { install.packages(setdiff(packages, rownames(installed.packages())), repos = &quot;http://cran.us.r-project.org&quot;) } invisible(lapply(packages, library, character.only = TRUE)) We have automatically generated a downloadable bibliography of the R package versions used in this companion for later reproducibility. knitr::write_bib(c( .packages(), &quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot; ), &quot;external/hitchhikers-guide-packages.bib&quot;) Download Bibliography file "],["02-canonical.html", "Canonical Models Multilevel Model Generalized Additive Mixed Model Latent Curve Model Latent Change Score Model", " Canonical Models What follows are canonical versions of growth models in each of the four different frameworks. These models represent basic implementations of a linear growth trajectory with random effects for both the intercept and slope, with the exception of the GAMM, where a non-linear spline model is implemented (otherwise it would just re-capitulate the MLM results). This will be the longest chapter of the codebook since we will cover syntax and model output more in-depth than in later chapters. Remain calm and clutch your towel as necessary. First, we need to read in the datasets we will use in this chapter. executive.function &lt;- utils::read.csv(&quot;data/executive-function.csv&quot;, header = TRUE) %&gt;% select(id, dlpfc1:dlpfc4) executive.function.long &lt;- executive.function %&gt;% tidyr::pivot_longer(cols = starts_with(&quot;dlpfc&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% dplyr::mutate(wave = as.numeric(wave) - 1) feedback.learning &lt;- read.csv(&quot;data/feedback-learning.csv&quot;) %&gt;% select(id, age, modularity) While we will usually read in the wide and long versions of the data directly, here we will demonstrate how to reformat the more common wide data format (i.e., each row corresponds to a different individual and repeated measures are new variables) into the long data format (i.e., each row corresponds to a different repeated measure with multiple rows per person). We can use the pivot_longer() function from the tidyr package (alternatives include melt() from the reshape package). We will collect all the columns that begin with the string dlpfc and pass the values into one column, while creating a new column wave from their number indices (e.g., 1 for dlpfc1). We can then use the mutate() function from the dplyr package to change the wave colum from a character to a numeric variable and subtract \\(1\\) from every value so that the first wave is coded as \\(0\\) (this will be important for interpretations later). Details regarding these datasets can be found in Datasets. However, shortly, the executive-function.csv file contains data for \\(342\\) adolescents measured up to \\(4\\) times. At each wave, adolescents played an executive function task while in an fMRI scanner. For now, we will only use the DLPFC measures to build the canonical growth models. The first \\(5\\) individuals are shown below. These data are in wide format. executive.function %&gt;% filter(id &lt;= 5) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Executive Function Data: Wide Format**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Executive Function Data: Wide Format id dlpfc1 dlpfc2 dlpfc3 dlpfc4 1 -0.184 1.129 -0.840 0.472 2 0.801 1.129 0.801 1.457 3 0.472 1.129 0.144 0.144 4 0.472 0.472 0.472 0.472 5 -0.840 2.114 2.442 2.442 We can then see what this looks like in long format. executive.function.long %&gt;% filter(id &lt;= 5) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Executive Function Data: Long Format**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Executive Function Data: Long Format id wave dlpfc 1 0 -0.184 1 1 1.129 1 2 -0.840 1 3 0.472 2 0 0.801 2 1 1.129 2 2 0.801 2 3 1.457 3 0 0.472 3 1 1.129 3 2 0.144 3 3 0.144 4 0 0.472 4 1 0.472 4 2 0.472 4 3 0.472 5 0 -0.840 5 1 2.114 5 2 2.442 5 3 2.442 The feedback-learning.csv file contains data for \\(297\\) adolescents and young adults measured up to \\(3\\) times. At each wave, individuals played a feedback learning task while in an fMRI scanner. ROI timeseries were then used to construct a brain network graph and the modularity of that graph was calculated. Here we will focus on these modularity values. The first \\(5\\) individuals are shown below. feedback.learning %&gt;% filter(id &lt;= 5) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Feedback Learning Data**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Feedback Learning Data id age modularity 1 20.43 0.117 2 16.70 0.127 2 18.65 0.148 2 20.65 0.143 3 22.68 0.124 3 24.68 0.162 3 26.77 0.107 4 11.63 0.102 4 13.86 0.154 4 15.87 0.154 5 16.50 0.158 5 18.48 0.185 5 20.44 0.183 Before we move into fitting the growth models in each of the four frameworks, we can begin by exporting the data to SAS and Mplus compatible file types. We will use the MplusAutomation package to write our Rdata into a .dat file. We have wrapped the command in the capture.output() function so that we can retain a record of the column names (Mplus does not accept files with headers) to prevent referencing the wrong variable when we run our model. The output of the MplusAutomation command prepareMplusData() will be saved in a text file in the same external directory. filename &lt;- &quot;executive-function&quot; capture.output( MplusAutomation::prepareMplusData(executive.function, paste0(&quot;external/&quot;,filename,&quot;.dat&quot;)), file=paste0(&quot;external/&quot;,filename,&quot;_MplusAutomation.txt&quot;)) Although we do not show the running and output of these models in-depth, all the Mplus files needed to recreate the MLM and SEM models are available to be downloaded below. Download Mplus files For readers interested in how to automate running Mplus models through R, please consult the extrememly useful functions in MplusAutomation that allow you to generate syntax, run saved input files, and re-import Mplus models into the R environment. Please note that a local Mplus license is still necessary to run these models. We can also use the package foreign to write out the data to a SAS compatible text file. The write.foreign() function also outputs a syntax file that imports the data into the SAS environment. foreign::write.foreign(executive.function.long, datafile = paste0(&quot;external/&quot;,filename,&quot;.txt&quot;), codefile = paste0(&quot;external/import_&quot;,filename,&quot;.sas&quot;), package=&quot;SAS&quot;) For convenience, all the SAS files needed to recreate the MLM analyses are available for download below. Download SAS files Multilevel Model We will start with the multilevel growth model using our executive.function data. There are a number of package options to fit multilevel models, but we will focus here on two of the most popular: nlme and lme4. We will also use the lmerTest package which outputs p-values for the tests, which are not included in the lme4 package. We will fit a very simple linear model with a random intercept and slope for the DLPFC activation data using all of these packages. For these initial models, we will mostly use wave as our metric of time rather than age for simplicity. We will return to models which use different time variables in later sections. nlme The nlme function lme() separates its syntax into a fixed and random argument using the standard glm() syntax common to R. In the random argument, we indicate that the random intercept (1) and random slope (wave) are nested within id using the pipe (|) character. We will indicate that rows with missing data will be omitted using na.action = na.omit and set the estimator to REstricted Maximum Likelihood (REML). For a discussion of REML versus Full Information Maximum Likelihood (FIML; set method = \"ML\"), see more information here. Once the model is finished running, we can print the model output to the console using the summary() function. Here we use the argument correlation=FALSE to suppress the correlation of fixed effects output, which is unlikely to be of interest to applied researchers. mlm.nlme &lt;- nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, na.action = na.omit, method = &quot;REML&quot;, data = executive.function.long) summary(mlm.nlme, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: executive.function.long ## AIC BIC logLik ## 3510.473 3541.503 -1749.236 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8120176 (Intr) ## wave 0.2231279 -0.354 ## Residual 0.7024454 ## ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5458598 0.05440921 961 10.032490 0 ## wave 0.1185110 0.02132837 961 5.556492 0 ## Correlation: ## (Intr) ## wave -0.545 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.8835588 -0.5108207 -0.0265644 0.5325893 2.6759419 ## ## Number of Observations: 1304 ## Number of Groups: 342 The first section of the model output shows the loglikelihood (logLik) and associated absolute fit indices (AIC and BIC). The Random effects section shows parameter estimtaes of the standard deviations (StdDev) and correlations (Corr) of the random effects (the identities are denoted by labels to the left of the matrix), as well as the level-1 error standard deviation (Residual). We can see that the standard deviation of the random intercept (\\(StdDev = 0.812\\)) is substantially larger than that of the random slope (\\(StdDev = 0.223\\)). This is often the case and has more to do with the scaling of the effect than anything else. The correlation between the random effects (\\(Corr = -0.354\\)) suggests that individual with higher initial levels of DLPFC activation show lower slope values . We will need to interpret this in the context of the fixed effects (e.g., are the slopes less positive, or more negative?), and plotting the predicted effects is often useful for this interpretation. The Fixed effects section contains the regression estimates of our fixed effects. Here we can see that the average value of DLPFC activation at the intercept is \\(0.546\\). Because we coded the wave predictor to have values of \\(0\\) at the first measurement occasion, this means that the intercept corresponds to initial DLPFC activation. Of course, the units here aren”t meaningful, but initial status is often (but not always) the desired interpretation of the intercept term. Here the slope is positive and significant (\\(\\gamma_{wave} = .199, SE = 0.021, p &lt; .001\\)). The final section contains information about the number of observations and number of groups, which are good values to check to ensure that the nesting of the data in the model corresponds to expectations. lme4 The lmer() function has largely supplanted lme() in most applications of multilevel models. Here, the formula is contained within a single line but is largely the same format. Additionally, the method = \"REML\" argument has been changed to REML = TRUE (REML = FALSE gives us FIML). mlm.lme4 &lt;- lme4::lmer(dlpfc ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = executive.function.long) summary(mlm.lme4, correlation = FALSE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: dlpfc ~ 1 + wave + (1 + wave | id) ## Data: executive.function.long ## ## REML criterion at convergence: 3498.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.88358 -0.51082 -0.02656 0.53257 2.67596 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.65939 0.8120 ## wave 0.04979 0.2231 -0.35 ## Residual 0.49342 0.7024 ## Number of obs: 1304, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.54586 0.05441 10.032 ## wave 0.11851 0.02133 5.556 The main differences in the output are that lmer() gives the variance of the random effects in addition to the standard deviations, and that there are no longer p-values associated with the fixed effects. However, all the values are identical to the lme() solution (which should make us sigh in relief). lmerTest If we wish to retain p-values in our solution, we can load the package lmerTest and use its version of lmer() to fit the model. The syntax is identical to what we used above, and the parameter estimates are as well. mlm.lmerTest &lt;- lmerTest::lmer(dlpfc ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = executive.function.long) summary(mlm.lmerTest, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: dlpfc ~ 1 + wave + (1 + wave | id) ## Data: executive.function.long ## ## REML criterion at convergence: 3498.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.88358 -0.51082 -0.02656 0.53257 2.67596 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.65939 0.8120 ## wave 0.04979 0.2231 -0.35 ## Residual 0.49342 0.7024 ## Number of obs: 1304, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.54586 0.05441 340.07130 10.032 &lt; 2e-16 *** ## wave 0.11851 0.02133 331.21032 5.556 5.67e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 MLM Outputs The summary() function output, while extensive, is not formatted for publication. However, we can use a great function tab_model() from the sjPlot package to generate publication-quality tables from the MLM output. Here we will merge the results from the nlme and lmerTest packages. sjPlot::tab_model(mlm.nlme, mlm.lmerTest, show.se = TRUE, show.df = FALSE, show.ci = FALSE, digits = 3, pred.labels = c(&quot;Intercept&quot;, &quot;Wave&quot;), dv.labels = c(&quot;nlme&quot;, &quot;lme4&quot;), string.se = &quot;SE&quot;, string.p = &quot;P-Value&quot;)   nlme lme4 Predictors Estimates SE P-Value Estimates SE P-Value Intercept 0.546 0.054 &lt;0.001 0.546 0.054 &lt;0.001 Wave 0.119 0.021 &lt;0.001 0.119 0.021 &lt;0.001 Random Effects σ2 0.49 0.49 τ00 0.66 id 0.66 id τ11 0.05 id.wave 0.05 id.wave ρ01 -0.35 id -0.35 id ICC 0.57 0.57 N 342 id 342 id Observations 1304 1304 Marginal R2 / Conditional R2 0.015 / 0.572 0.015 / 0.572 If we wish, we can output the table into a file that we can use to incorporate it into a document using the argument file = \"/path/to/output/sjPlot_table.html\". MLM Plotting Model-Implied Trajectories If we want to plot the model-implied trajectories for each individual, we can use the ggplot2 package. To plot data, we need to have it in long format. Fortunately this is the format used in the MLM model so we don”t need to do anything additional. We will plot predicted values generated from the predict() function. While we could append these values to our executive.function.long dataframe in a separate step, we will instead generate the values locally within the ggplot() function. This will save us a step and we won”t have to deal with merging the predicted values into our dataframe or having to remove those values later. Because MLMs drop NA values, our predicted values will not match up to the original dataframe unless we also drop thos NA values, so we will use the drop_na() function from tidyr. ggplot2::ggplot(tidyr::drop_na(executive.function.long), aes(x = wave + 1, y = predict(mlm.lmerTest), group = id, color = factor(id))) + geom_line() + labs(title = &quot;Canonical MLM Trajectories&quot;, x = &quot;Wave&quot;, y = &quot;Predicted DLFPC Activation&quot;) + theme(legend.position = &quot;none&quot;) We can see that there is quite a bit of individual differences both in the initial level, but also in slopes across time, with some individuals showing increases but other showing no change or even decreases across waves. A quick tip is to always use the theme(legend.position = \"none\") function in this kind of plot unless you want the plot to try to show you each individual with the color of their trajectory line. Generalized Additive Mixed Model We can move on to fitting a GAMM model. Unlike the other frameworks, we will use the feedbacklearn data with continuous age across 2 decades in this model. We could, in theory, fit the executive.function data, but that would largely be a waste of the GAMM framework”s potential for longitudinal analysis. Here we will utilize the gamm4 package for fitting GAMMs with the gamm4() function, although other options (e.g., gamm() or gam() from the mgcv package). Fortunately, the gamm4() uses syntax that we are largely familiar with from fitting the MLMs in the prior section. Here we will begin by fitting a simple smooth function for values of network modularity across age. Note here that we standardize the modularity values since the natural scale results in very small variance components, and the units of modularity are not naturally meaningful anyways. To invoke the smoothing function, we wrap the age predictor with the s() function in the formula. Note that the random effects argument resembles the nlme syntax. For now we will allow many of the defaults to kick in, but will investigate them in turn. gamm &lt;- gamm4::gamm4(scale(modularity) ~ 1 + s(age), random = ~ (1 | id), data = feedback.learning) Unlike the MLM models, the GAMM results in two sets of model results from linear and nonlinear parts of the model. To access the linear model we need to specify the mer part of the model output. summary(gamm$mer, correlation = FALSE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## ## REML criterion at convergence: 1838.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2280 -0.5682 -0.0059 0.5675 2.5224 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.4795 0.6925 ## Xr s(age) 1.8083 1.3447 ## Residual 0.3762 0.6134 ## Number of obs: 754, groups: id, 297; Xr, 8 ## ## Fixed effects: ## Estimate Std. Error t value ## X(Intercept) -0.009532 0.046447 -0.205 ## Xs(age)Fx1 0.341061 0.223724 1.524 We will ignore the Fixed effects: portion of the output for now because our main effect of interest is the nonlinear smooth of age and we did not include additional linear effects (we will see this more later). Focusing on the Random effects:, we can see that there is a little more person-to-person variability (Groups = id, Name = (Intercept)) than within-person variability (Groups = Residual), but they are roughly equivalent. Note that we have an “extra” random effect (Groups = Xr, Name = s(age)). Although this might lead us to believe that we have included a random within-person slope, but it is a formulation of the smooth itself as a random effect and is not terribly informative here. We could include a true random effect of age by expanding the formula in the random argument (random = ~ (1 + age | id)), but that model is not identified in this data and so we won’t. We can then take a look at the nonlinear portion of the output by summarizing the gam portion of the model. summary(gamm$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## scale(modularity) ~ 1 + s(age) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.009532 0.046447 -0.205 0.837 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 4.647 4.647 28.18 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.162 ## lmer.REML = 1838.4 Scale est. = 0.37624 n = 754 As before, we will mostly ignore the Parametric coefficients: portion (although see that the (Intercept) estimate is identical; this should be of concern if this wasn’t the case). The Approximate significance of smooth terms: portion shows that we have a significant effect of age with a estimated degrees of freedom (EDF) of \\(4.65\\). The EDF give us a shrunken estimate of the smooth complexity (higher values indicate greater complexity). However, this isn’t incredibly helpful to understand the nature of the developmental effect. Instead, let’s turn to the output options and see what we can find there. GAMM Outputs Just like with MLMs, we can generate pretty tables instead of just manually typing out the console output into a word processor. We can use the tab_model() for the mer part of the output, but we need to call the gamtabs() function from the itsadug package for the gam section. itsadug::gamtabs(gamm$gam, type = &quot;html&quot;, pnames = c(&quot;Intercept&quot;), snames = c(&quot;s(Age)&quot;), caption = &quot;Modularity as a Function of Age&quot;) Modularity as a Function of Age A. parametric coefficients Estimate Std. Error t-value p-value Intercept -0.0095 0.0464 -0.2052 0.8375 B. smooth terms edf Ref.df F-value p-value s(Age) 4.6471 4.6471 28.1838 &lt; 0.0001 To visualize the results, we can call the plot.gam() function from the mgcv package (which aliases as plot() when the mgcv package is loaded). We can include the standard errors and a rug plot to show the individual age observations in our data. This can help us identify regions of the estimated trajectory that are more or less supported by the data in addition to the standard error width. mgcv::plot.gam(gamm$gam, se = TRUE, rug = TRUE, shade = TRUE, xlab = &quot;Age&quot;, ylab = &quot;Fitted Modularity Values&quot;) The resulting plot tells a rather interesting story about the developmental trajectory of modularity, with initial increases across early adolescence, a plateauing in mid-adolescence, and then slow declines into young adulthood. However, we can see there is a lot more uncertainty at the later ages (indicated by the sparsity in the hashes in the rug plot). Latent Curve Model We will now turn to the longitudinal modeling within the SEM framework, beginning with the latent curve model (or latent growth model; quantitative people aren”t the best with consistent terminology sometimes). Unlike with the mixed-effects models, we will focus on a single package, lavaan, which has become the workhorse of structural equation modeling natively in R (for running SEMs in Mplus using R commands, see the MplusAutomation package). Like with the MLM, we will fit a simple linear growth model using wave as our metric of time. However, unlike with the MLM, time will not appear as a specific variable in the model; rather we code time measurements directly into the factor loadings. LCM Syntax and Model Fitting First we will define a model syntax object that specifies the model. While we will cover the basics here, consult the lavaan website for a more complete syntax tutorial. linear.lcm &lt;- &quot; # Define the Latent Variables int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 # Define Factor Means int ~ 1 slp ~ 1 # Define Factor (Co)Variances int ~~ int int ~~ slp slp ~~ slp # Define Indicator Residual Variances dlpfc1 ~~ dlpfc1 dlpfc2 ~~ dlpfc2 dlpfc3 ~~ dlpfc3 dlpfc4 ~~ dlpfc4 &quot; In the first section, we use the =~ operator to define the latent variables (int is the intercept and slp is the linear slope factor). The intercept factor loadings are set by pre-multiplying the individual indicators (dlpfc1-dlpfc4) by values of \\(1\\). We define the slope by pre-multiplying the indicators by linearly increasing values. Here we set the first factor loading to \\(0\\) and each subsequent loading by increasing integers. This has the effect of estimating intercept values that reflect levels of DLPFC activation at the initial observation (where time is coded \\(0\\)) and a slope effect that is expressed in per-wave units (here this relates to per-year changes). Because of defaults built into the lavaan function growth(), we could estimate the full linear LCM with just these first two lines of code (the Mplus syntax is similarly simple). However, for completeness, we will write out the remainder of the model parameters for this initial model. The next two sections define the parameters of the latent variables. Here we estimate intercepts (i.e., the fixed or average intercept and slope) using the regression operator (~) with \\(1\\) on the right hand side and (co)variances using the ~~ operator. Note that variances int ~~ int are just the covariance of a variable with itself (take a shot if that makes your head hurt a little bit). Finally, we can define the residual variances of the indicators using the same ~~ operator. We can then use the growth() function mentioned previously to fit the syntax we wrote to the executive.function data. Here we will estimate the model with Maximum Likelihood (estimator = \"ML\") and we will allow for missing data using the missing = \"FIML\" argument. Standard alternatives might include estimator = \"MLR\" for Robust Maximum Likelihood if we have non-normal continuous data, or estimator = WLSMV if we have discrete data (see the lavaan webpage for a full list of available options). In general, we will always allow for missing data, but we could change to missing = \"listwise\" if we wanted to do only complete-case analysis. This option is actually the lavaan default, so users should be cautious that this is intended and review the number of observations used in the model to confirm intended behavior. lcm &lt;- lavaan::growth(linear.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) LCM Outputs We can then summarize the model output using summary() with some optional arguments. While we will mostly output all of the available information, including fit.measures, raw (estimates) and standardized (standardize) parameter estimates, and rsquare, there might be cases where we are only interested in some subsection of the output. For instance, if we are building a sequence of models, we might only consult fit measures without viewing the parameters and associated inference tests so that our model selection isn”t driven by “peeking” at effects of interest. summary(lcm, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.229 ## Degrees of freedom 5 ## P-value (Chi-square) 0.942 ## ## Model Test Baseline Model: ## ## Test statistic 381.370 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.012 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 ## Loglikelihood unrestricted model (H1) -1735.170 ## ## Akaike (AIC) 3489.570 ## Bayesian (BIC) 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.014 ## P-value RMSEA &lt;= 0.05 0.990 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## dlpfc1 1.000 0.880 ## dlpfc2 1.000 0.880 ## dlpfc3 1.000 0.880 ## dlpfc4 1.000 0.880 ## slp =~ ## dlpfc1 0.000 0.000 ## dlpfc2 1.000 0.287 ## dlpfc3 2.000 0.574 ## dlpfc4 3.000 0.861 ## Std.all ## ## 0.878 ## 0.813 ## 0.810 ## 0.820 ## ## 0.000 ## 0.265 ## 0.528 ## 0.802 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp -0.126 0.031 -4.102 0.000 -0.499 ## Std.all ## ## -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int 0.543 0.053 10.181 0.000 0.617 ## slp 0.121 0.021 5.705 0.000 0.420 ## .dlpfc1 0.000 0.000 ## .dlpfc2 0.000 0.000 ## .dlpfc3 0.000 0.000 ## .dlpfc4 0.000 0.000 ## Std.all ## 0.617 ## 0.420 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int 0.775 0.086 9.009 0.000 1.000 ## slp 0.082 0.016 5.180 0.000 1.000 ## .dlpfc1 0.231 0.063 3.675 0.000 0.231 ## .dlpfc2 0.568 0.055 10.261 0.000 0.568 ## .dlpfc3 0.582 0.058 10.117 0.000 0.582 ## .dlpfc4 0.393 0.074 5.308 0.000 0.393 ## Std.all ## 1.000 ## 1.000 ## 0.229 ## 0.484 ## 0.493 ## 0.341 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## dlpfc2 0.516 ## dlpfc3 0.507 ## dlpfc4 0.659 One nice thing about fitting our model to the raw data instead of standardizing beforehand is that with the standardize = TRUE argument, we get 3 sets of parameter estimates: the raw scale estimates (under Estimates), the estimates when the latent variables are standardized but the indicators remain in the raw scale (under Std.lv), and the fully standardized solution (under Std.all). In the same spirit of maximizing the information from the model, we can actually re-fit the model using estimator = \"MLR\". Here we will only output the fit.measures to see how the robust estimator changes our model fit information. lcm &lt;- lavaan::growth(linear.lcm, data = executive.function, estimator = &quot;MLR&quot;, missing = &quot;FIML&quot;) summary(lcm, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## Standard Robust ## Test Statistic 1.229 1.139 ## Degrees of freedom 5 5 ## P-value (Chi-square) 0.942 0.951 ## Scaling correction factor 1.079 ## Yuan-Bentler correction (Mplus variant) ## ## Model Test Baseline Model: ## ## Test statistic 381.370 305.720 ## Degrees of freedom 6 6 ## P-value 0.000 0.000 ## Scaling correction factor 1.247 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 1.000 ## Tucker-Lewis Index (TLI) 1.012 1.015 ## ## Robust Comparative Fit Index (CFI) 1.000 ## Robust Tucker-Lewis Index (TLI) 1.013 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 -1735.785 ## Scaling correction factor 1.135 ## for the MLR correction ## Loglikelihood unrestricted model (H1) -1735.170 -1735.170 ## Scaling correction factor 1.115 ## for the MLR correction ## ## Akaike (AIC) 3489.570 3489.570 ## Bayesian (BIC) 3524.083 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 0.000 ## 90 Percent confidence interval - lower 0.000 0.000 ## 90 Percent confidence interval - upper 0.014 0.000 ## P-value RMSEA &lt;= 0.05 0.990 0.994 ## ## Robust RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 0.016 We can see that we get a new column of robust fit statistics to accompany the standard measures which correct for the non-normality in our data. In this case, our data are not too non-normal and so there is little difference. However, this will not always be the case. To vastly over-simplify, we are looking to see if our Model Test User Model: test statistic is non-significant. However, be aware that this test is over-powered and will often be significant in large samples, even in a well fitting model. We also tend to look for CFI/TLI \\(&gt; 0.95\\), RMSEA \\(&lt; 0.05\\), and SRMR \\(&lt; 0.08\\) to indicate an excellent model fit. While these cutoff values are somewhat arbitrary, they can serve as a rough huristic, and the linear LCM more than satisfies each of these criteria. For more discussion of fit indices, consult the resources outlined in the main text. We can now jump back and orient to the parameter estimate output. summary(lcm, fit.measures = FALSE, estimates= TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## Standard Robust ## Test Statistic 1.229 1.139 ## Degrees of freedom 5 5 ## P-value (Chi-square) 0.942 0.951 ## Scaling correction factor 1.079 ## Yuan-Bentler correction (Mplus variant) ## ## Parameter Estimates: ## ## Standard errors Sandwich ## Information bread Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## dlpfc1 1.000 0.880 ## dlpfc2 1.000 0.880 ## dlpfc3 1.000 0.880 ## dlpfc4 1.000 0.880 ## slp =~ ## dlpfc1 0.000 0.000 ## dlpfc2 1.000 0.287 ## dlpfc3 2.000 0.574 ## dlpfc4 3.000 0.861 ## Std.all ## ## 0.878 ## 0.813 ## 0.810 ## 0.820 ## ## 0.000 ## 0.265 ## 0.528 ## 0.802 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp -0.126 0.037 -3.406 0.001 -0.499 ## Std.all ## ## -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int 0.543 0.053 10.180 0.000 0.617 ## slp 0.121 0.021 5.704 0.000 0.420 ## .dlpfc1 0.000 0.000 ## .dlpfc2 0.000 0.000 ## .dlpfc3 0.000 0.000 ## .dlpfc4 0.000 0.000 ## Std.all ## 0.617 ## 0.420 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int 0.775 0.093 8.335 0.000 1.000 ## slp 0.082 0.017 4.761 0.000 1.000 ## .dlpfc1 0.231 0.075 3.060 0.002 0.231 ## .dlpfc2 0.568 0.057 9.884 0.000 0.568 ## .dlpfc3 0.582 0.062 9.332 0.000 0.582 ## .dlpfc4 0.393 0.076 5.138 0.000 0.393 ## Std.all ## 1.000 ## 1.000 ## 0.229 ## 0.484 ## 0.493 ## 0.341 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## dlpfc2 0.516 ## dlpfc3 0.507 ## dlpfc4 0.659 The first section of parameters Latent Variables: is of little interest to us for now since we pre-determined these factor loadings as a part of our model (but maybe check that they are the values you expect) and there are therefore no inferential tests on these parameters. The Covariances: section shows us the covariance (and correlation if we asked for standardized results) between the intercept and slope. Here we can see that the correlation is strong and negative (\\(r = -0.499\\)) suggesting that those with the lowest initial levels of DLPFC activation tend to show the strongest increases in activation over time. The Intercepts: section shows us the means of the latent factors and would show the conditional (denoted by a . before a variable name) intercepts of the indicators, but we do not estimate these values in a growth model (rather the means are reproduced by the factor means through the loadings, \\(\\mathbf{\\alpha\\Lambda}\\)). Here we can see that the average activation at the initial timepoint is \\(0.543\\) and the average rate of change is \\(0.121\\) units per wave, both of which are significant. Next we have the factor variances and the indicator residual (again denoted with .) variances in the Variances: section. The variances of the intercept and slope are significant suggesting there are meaningful individual differences in initial level and rate of change over time. The residual variances comprise the variance of the indicator not accounted for by the latent variables in the model. Finally, we have the R-Square: section where the proportion of variance explained in each of the endogenous variables (here just the indicators but this could contain other endogenous observed or latent variables in other models). Conveniently, this is simply \\(1\\) minus the standardized residual variance for each item. We can output these parameters in a slightly more compact format using the tidy() function from the broom package and pass it to the kable() function from the kableExtra package to output a table in the \"html\" format. If we were writing a manuscript, we might alternatively wish to output the rmarkdown in PDF form and use the format = \"latex\" argument. broom::tidy(lcm) %&gt;% select(-op, -std.nox) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Linear Latent Curve Model**&quot;, align = &quot;c&quot;, col.names=c(&quot;Parameter&quot;, &quot;Estimate&quot;, &quot;SE&quot;, &quot;Statistic&quot;, &quot;*p*-value&quot;, &quot;Std.LV&quot;, &quot;Std.All&quot;), row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Linear Latent Curve Model Parameter Estimate SE Statistic p-value Std.LV Std.All int =~ dlpfc1 1.000 0.000 NA NA 0.880 0.878 int =~ dlpfc2 1.000 0.000 NA NA 0.880 0.813 int =~ dlpfc3 1.000 0.000 NA NA 0.880 0.810 int =~ dlpfc4 1.000 0.000 NA NA 0.880 0.820 slp =~ dlpfc1 0.000 0.000 NA NA 0.000 0.000 slp =~ dlpfc2 1.000 0.000 NA NA 0.287 0.265 slp =~ dlpfc3 2.000 0.000 NA NA 0.574 0.528 slp =~ dlpfc4 3.000 0.000 NA NA 0.861 0.802 int ~1 0.543 0.053 10.180 0.000 0.617 0.617 slp ~1 0.121 0.021 5.704 0.000 0.420 0.420 int ~~ int 0.775 0.093 8.335 0.000 1.000 1.000 int ~~ slp -0.126 0.037 -3.406 0.001 -0.499 -0.499 slp ~~ slp 0.082 0.017 4.761 0.000 1.000 1.000 dlpfc1 ~~ dlpfc1 0.231 0.075 3.060 0.002 0.231 0.229 dlpfc2 ~~ dlpfc2 0.568 0.057 9.884 0.000 0.568 0.484 dlpfc3 ~~ dlpfc3 0.582 0.062 9.332 0.000 0.582 0.493 dlpfc4 ~~ dlpfc4 0.393 0.076 5.138 0.000 0.393 0.341 dlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 LCM Path Diagrams We might also wish to generate a diagram visualization of the LCM model, either for model checking or for presenting results. We can use the semPaths() function from the semPlot package to do just that. Here we will plot the model results including the intercepts and with black paths. The what argument we will set to \"est\" to scale the size of the paths to the parameter estimate. semPlot::semPaths(lcm, what = &quot;est&quot;, intercepts = TRUE, edge.color = &quot;black&quot;) However, we can see that this path scaling is a little unfortunate because the integer factor loadings sort of swamp out the parameters we are primarily interested in. Instead we can change this argument to what = \"paths\" to have equally-sized paths, and then label those paths with the parameters using whatLabels = \"est\" (or whatLabels = \"std\" for standardized estimates). semPlot::semPaths(lcm, what = &quot;paths&quot;, whatLabels = &quot;est&quot;, intercepts = TRUE, edge.color = &quot;black&quot;) Much better… By standard convention, latent variables are represented as circles, observed variables as squares, regression paths as straight single-headed arrows, and (co)variances as curved double-headed arrows. Parameters that are set to particular values rather than estimated (e.g., factor loadings here and indicator intercepts) are displayed with dashed lines. LCM Plotting Model-Implied Trajectories Finally, like with the MLM, we might want to plot model-implied individual trajectories of DLPFC activation. We have to do a little data management song and dance to get the predicted values and then convert to long format (which we do within the ggplot() function directly instead of creating a new dataframe to store in memory), but the results are the same as before. ggplot2::ggplot(data.frame(id=lcm@Data@case.idx[[1]], lavPredict(lcm,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;dlpfc&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% dplyr::mutate(wave = as.numeric(wave)), aes(x = wave, y = dlpfc, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Canonical LCM Trajectories&quot;, x = &quot;Wave&quot;, y = &quot;Predicted DLFPC Activation&quot;) + theme(legend.position = &quot;none&quot;) Latent Change Score Model Finally, we can turn the LCSM parameterization of the linear growth model. Like the LCM, the time predictor will not appear in our model syntax, but even more strangely (at first), neither will any values of time. Rather we will sum across latent change factors to estimate the slope across time. Linear LCSM The main complication of the LCSM syntax relative to what we saw with the LCM is that we need to generate phantom variables from the indicators and then relate them with fixed path coefficients to the latent change factors. linear.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; In the first section, we define the phantoms (e.g., pdlpfc1) with four commands (separated by ; for compactness): 1) define the phantom by the indicator with a factor loading of \\(1\\) (pdlpfc1 =~ 1*dlpfc1), 2) set the intercept of the indicator to \\(0\\) (dlpfc1 ~ 0), 3) estimate the residual variance of the indicator (dlpfc1 ~~ dlpfc1), and set the variance of the phatom to \\(0\\) (pdlpfc1 ~~ 0*pdlpfc1). This, in effect, pushes the characteristics we need from the indicator variable to the phantom, which facilitates the model. In the nexttwo sections, we set regressions of \\(\\gamma = 1\\) between adjacent phantoms variables, define the latent change factor by the phantoms after the initial time point (e.g., delta21 =~ 1*pdlpfc2), and set the variance of the latent change factor to zero. This may not be apparent at first blush, but the regressions of \\(1\\) between adjacent timepoints essentially push the differences in the outcome between observations up into the latent change factors (i.e., what is left over after residualizing out the prior observation). Finally, we have the final definition of the intercept and slope factors. However, unlike the LCM, the intercept factor is only estimated from the initial phantom variable. The slope factor is defined from the latent change factors, but instead of linear factor loadings, all of these loadings are \\(1\\) (this sums across the latent changes to give the overall linear trajectory). Like before, we will take this syntax object and use it to fit the model we specify. Unlike the LCM, we will use the sem() function instead because the growth() defaults won”t serve our purposes with the LCSM. Otherwise, the arguments we will invoke will be the same. While we display it for completeness, we will not spend much time on this output as it exactly recreates the estimates for the LCM we already walked through (we promise; or scroll back up and check). We generate a path diagram for this model as well, but do not display parameter estimates to reduce clutter. lcsm.linear &lt;- sem(linear.lcsm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcsm.linear, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.229 ## Degrees of freedom 5 ## P-value (Chi-square) 0.942 ## ## Model Test Baseline Model: ## ## Test statistic 381.370 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.012 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 ## Loglikelihood unrestricted model (H1) -1735.170 ## ## Akaike (AIC) 3489.570 ## Bayesian (BIC) 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.014 ## P-value RMSEA &lt;= 0.05 0.990 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pdlpfc1 =~ ## dlpfc1 1.000 0.880 ## pdlpfc2 =~ ## dlpfc2 1.000 0.778 ## pdlpfc3 =~ ## dlpfc3 1.000 0.775 ## pdlpfc4 =~ ## dlpfc4 1.000 0.872 ## delta21 =~ ## pdlpfc2 1.000 0.369 ## delta32 =~ ## pdlpfc3 1.000 0.370 ## delta43 =~ ## pdlpfc4 1.000 0.329 ## int =~ ## pdlpfc1 1.000 1.000 ## slp =~ ## delta21 1.000 1.000 ## delta32 1.000 1.000 ## delta43 1.000 1.000 ## Std.all ## ## 0.878 ## ## 0.718 ## ## 0.712 ## ## 0.812 ## ## 0.369 ## ## 0.370 ## ## 0.329 ## ## 1.000 ## ## 1.000 ## 1.000 ## 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pdlpfc2 ~ ## pdlpfc1 1.000 1.132 ## pdlpfc3 ~ ## pdlpfc2 1.000 1.004 ## pdlpfc4 ~ ## pdlpfc3 1.000 0.889 ## Std.all ## ## 1.132 ## ## 1.004 ## ## 0.889 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp -0.126 0.031 -4.102 0.000 -0.499 ## Std.all ## ## -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .dlpfc1 0.000 0.000 ## .dlpfc2 0.000 0.000 ## .dlpfc3 0.000 0.000 ## .dlpfc4 0.000 0.000 ## int 0.543 0.053 10.181 0.000 0.617 ## slp 0.121 0.021 5.705 0.000 0.420 ## .pdlpfc1 0.000 0.000 ## .pdlpfc2 0.000 0.000 ## .pdlpfc3 0.000 0.000 ## .pdlpfc4 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.617 ## 0.420 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .dlpfc1 0.231 0.063 3.675 0.000 0.231 ## .pdlpfc1 0.000 0.000 ## .dlpfc2 0.568 0.055 10.261 0.000 0.568 ## .pdlpfc2 0.000 0.000 ## .dlpfc3 0.582 0.058 10.117 0.000 0.582 ## .pdlpfc3 0.000 0.000 ## .dlpfc4 0.393 0.074 5.308 0.000 0.393 ## .pdlpfc4 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## slp 0.082 0.016 5.180 0.000 1.000 ## int 0.775 0.086 9.009 0.000 1.000 ## Std.all ## 0.229 ## 0.000 ## 0.484 ## 0.000 ## 0.493 ## 0.000 ## 0.341 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.000 ## 1.000 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## pdlpfc1 1.000 ## dlpfc2 0.516 ## pdlpfc2 1.000 ## dlpfc3 0.507 ## pdlpfc3 1.000 ## dlpfc4 0.659 ## pdlpfc4 1.000 ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 broom::tidy(lcsm.linear) %&gt;% arrange(op) %&gt;% select(-op, -std.nox) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Linear Latent Change Score Model**&quot;, align = &quot;c&quot;, col.names=c(&quot;Parameter&quot;, &quot;Estimate&quot;, &quot;SE&quot;, &quot;Statistic&quot;, &quot;*p*-value&quot;, &quot;Std.LV&quot;, &quot;Std.All&quot;), row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Linear Latent Change Score Model Parameter Estimate SE Statistic p-value Std.LV Std.All pdlpfc1 =~ dlpfc1 1.000 0.000 NA NA 0.880 0.878 pdlpfc2 =~ dlpfc2 1.000 0.000 NA NA 0.778 0.718 pdlpfc3 =~ dlpfc3 1.000 0.000 NA NA 0.775 0.712 pdlpfc4 =~ dlpfc4 1.000 0.000 NA NA 0.872 0.812 delta21 =~ pdlpfc2 1.000 0.000 NA NA 0.369 0.369 delta32 =~ pdlpfc3 1.000 0.000 NA NA 0.370 0.370 delta43 =~ pdlpfc4 1.000 0.000 NA NA 0.329 0.329 int =~ pdlpfc1 1.000 0.000 NA NA 1.000 1.000 slp =~ delta21 1.000 0.000 NA NA 1.000 1.000 slp =~ delta32 1.000 0.000 NA NA 1.000 1.000 slp =~ delta43 1.000 0.000 NA NA 1.000 1.000 pdlpfc2 ~ pdlpfc1 1.000 0.000 NA NA 1.132 1.132 pdlpfc3 ~ pdlpfc2 1.000 0.000 NA NA 1.004 1.004 pdlpfc4 ~ pdlpfc3 1.000 0.000 NA NA 0.889 0.889 dlpfc1 ~~ dlpfc1 0.231 0.063 3.675 0 0.231 0.229 pdlpfc1 ~~ pdlpfc1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~~ dlpfc2 0.568 0.055 10.261 0 0.568 0.484 pdlpfc2 ~~ pdlpfc2 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~~ dlpfc3 0.582 0.058 10.117 0 0.582 0.493 pdlpfc3 ~~ pdlpfc3 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~~ dlpfc4 0.393 0.074 5.308 0 0.393 0.341 pdlpfc4 ~~ pdlpfc4 0.000 0.000 NA NA 0.000 0.000 delta21 ~~ delta21 0.000 0.000 NA NA 0.000 0.000 delta32 ~~ delta32 0.000 0.000 NA NA 0.000 0.000 delta43 ~~ delta43 0.000 0.000 NA NA 0.000 0.000 int ~~ slp -0.126 0.031 -4.102 0 -0.499 -0.499 slp ~~ slp 0.082 0.016 5.180 0 1.000 1.000 int ~~ int 0.775 0.086 9.009 0 1.000 1.000 dlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 int ~1 0.543 0.053 10.181 0 0.617 0.617 slp ~1 0.121 0.021 5.705 0 0.420 0.420 pdlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 delta21 ~1 0.000 0.000 NA NA 0.000 0.000 delta32 ~1 0.000 0.000 NA NA 0.000 0.000 delta43 ~1 0.000 0.000 NA NA 0.000 0.000 semPlot::semPaths(lcsm.linear, layout = &quot;tree2&quot;, intercepts = FALSE, edge.color = &quot;black&quot;) Linear LCSM with Proportional Change To a first approximation, the model above is an overly complicated method for estimating the same model we could do with two lines in the LCM. However, this parameterization allows us to include effects that are not possible to include in the LCM. To model proportional change, we regression the latent change factor on the prior timepoint phantom variable (delta21 ~ pdlpfc1). This effect tests how change between timepoints depends on prior level on the outcome of interest, and can be used to model interesting non-linearities (especially exponential trends). While not strictly necessary, it is common practice to create an equality constraint across all proportional effects. Here we accomplish this constraint by pre-multiplying all of these regressions with the same label (beta). The rest of the syntax remains the same as above. proportional.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Proportional Change Regressions (beta = equality constraint) delta21 ~ beta*pdlpfc1 delta32 ~ beta*pdlpfc2 delta43 ~ beta*pdlpfc3 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; lcsm.proportional &lt;- sem(proportional.lcsm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) We will just focus here on the parameter estimate for the proportional effect (beta), which is negative, but non-significant (\\(\\gamma = -0.090, SE = 0.276, p = 0.745\\)). If we were to interpret this parameter, we would say that those with higher levels at prior timepoints tend to show less positive changes between adjacent timepoints (we would need to interpret these in light of the fixed effects to be certain if this is smaller increases or greater decreases). Interestingly, note that this is similar in kind to the factor covariance we interpreted in the LCM. If we examine that same parameter here, we can see that the correlation has been attenuated (\\(r = -0.295\\)) and is now non-significant. Indeed all the parameter estimates have now changed because we have introduced this new proportional effect. summary(lcsm.proportional, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 32 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## Number of equality constraints 2 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.132 ## Degrees of freedom 4 ## P-value (Chi-square) 0.889 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## pdlpfc1 =~ ## dlpfc1 1.000 ## pdlpfc2 =~ ## dlpfc2 1.000 ## pdlpfc3 =~ ## dlpfc3 1.000 ## pdlpfc4 =~ ## dlpfc4 1.000 ## delta21 =~ ## pdlpfc2 1.000 ## delta32 =~ ## pdlpfc3 1.000 ## delta43 =~ ## pdlpfc4 1.000 ## int =~ ## pdlpfc1 1.000 ## slp =~ ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## pdlpfc2 ~ ## pdlpfc1 1.000 ## pdlpfc3 ~ ## pdlpfc2 1.000 ## pdlpfc4 ~ ## pdlpfc3 1.000 ## delta21 ~ ## pdlpfc1 (beta) -0.090 0.276 -0.325 0.745 ## delta32 ~ ## pdlpfc2 (beta) -0.090 0.276 -0.325 0.745 ## delta43 ~ ## pdlpfc3 (beta) -0.090 0.276 -0.325 0.745 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.074 0.162 -0.457 0.647 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.540 0.054 9.994 0.000 ## slp 0.179 0.183 0.981 0.326 ## .pdlpfc1 0.000 ## .pdlpfc2 0.000 ## .pdlpfc3 0.000 ## .pdlpfc4 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.208 0.102 2.043 0.041 ## .pdlpfc1 0.000 ## .dlpfc2 0.573 0.058 9.820 0.000 ## .pdlpfc2 0.000 ## .dlpfc3 0.577 0.060 9.570 0.000 ## .pdlpfc3 0.000 ## .dlpfc4 0.413 0.095 4.358 0.000 ## .pdlpfc4 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## slp 0.079 0.016 4.970 0.000 ## int 0.796 0.115 6.925 0.000 Like before, we can generate tables, a path diagram, and plot model-implied individual trajectories. Note that the proportional model does not generate noticeably non-linear implied trajectories due to the very weak proportional effect. broom::tidy(lcsm.proportional) %&gt;% arrange(op) %&gt;% select(-op, -std.nox) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Linear Latent Change Score Model with Proportional Change**&quot;, align = &quot;c&quot;, col.names=c(&quot;Parameter&quot;, &quot;Label&quot;, &quot;Estimate&quot;, &quot;SE&quot;, &quot;Statistic&quot;, &quot;*p*-value&quot;, &quot;Std.LV&quot;, &quot;Std.All&quot;), row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Linear Latent Change Score Model with Proportional Change Parameter Label Estimate SE Statistic p-value Std.LV Std.All pdlpfc1 =~ dlpfc1 1.000 0.000 NA NA 0.892 0.891 pdlpfc2 =~ dlpfc2 1.000 0.000 NA NA 0.777 0.716 pdlpfc3 =~ dlpfc3 1.000 0.000 NA NA 0.776 0.714 pdlpfc4 =~ dlpfc4 1.000 0.000 NA NA 0.861 0.802 delta21 =~ pdlpfc2 1.000 0.000 NA NA 0.405 0.405 delta32 =~ pdlpfc3 1.000 0.000 NA NA 0.370 0.370 delta43 =~ pdlpfc4 1.000 0.000 NA NA 0.303 0.303 int =~ pdlpfc1 1.000 0.000 NA NA 1.000 1.000 slp =~ delta21 1.000 0.000 NA NA 0.895 0.895 slp =~ delta32 1.000 0.000 NA NA 0.983 0.983 slp =~ delta43 1.000 0.000 NA NA 1.080 1.080 pdlpfc2 ~ pdlpfc1 1.000 0.000 NA NA 1.148 1.148 pdlpfc3 ~ pdlpfc2 1.000 0.000 NA NA 1.002 1.002 pdlpfc4 ~ pdlpfc3 1.000 0.000 NA NA 0.900 0.900 delta21 ~ pdlpfc1 beta -0.090 0.276 -0.325 0.745 -0.254 -0.254 delta32 ~ pdlpfc2 beta -0.090 0.276 -0.325 0.745 -0.243 -0.243 delta43 ~ pdlpfc3 beta -0.090 0.276 -0.325 0.745 -0.267 -0.267 dlpfc1 ~~ dlpfc1 0.208 0.102 2.043 0.041 0.208 0.207 pdlpfc1 ~~ pdlpfc1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~~ dlpfc2 0.573 0.058 9.820 0.000 0.573 0.487 pdlpfc2 ~~ pdlpfc2 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~~ dlpfc3 0.577 0.060 9.570 0.000 0.577 0.490 pdlpfc3 ~~ pdlpfc3 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~~ dlpfc4 0.413 0.095 4.358 0.000 0.413 0.357 pdlpfc4 ~~ pdlpfc4 0.000 0.000 NA NA 0.000 0.000 delta21 ~~ delta21 0.000 0.000 NA NA 0.000 0.000 delta32 ~~ delta32 0.000 0.000 NA NA 0.000 0.000 delta43 ~~ delta43 0.000 0.000 NA NA 0.000 0.000 int ~~ slp -0.074 0.162 -0.457 0.647 -0.295 -0.295 slp ~~ slp 0.079 0.016 4.970 0.000 1.000 1.000 int ~~ int 0.796 0.115 6.925 0.000 1.000 1.000 dlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 int ~1 0.540 0.054 9.994 0.000 0.605 0.605 slp ~1 0.179 0.183 0.981 0.326 0.637 0.637 pdlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 delta21 ~1 0.000 0.000 NA NA 0.000 0.000 delta32 ~1 0.000 0.000 NA NA 0.000 0.000 delta43 ~1 0.000 0.000 NA NA 0.000 0.000 semPlot::semPaths(lcsm.proportional, layout = &quot;tree2&quot;, intercepts = FALSE, edge.color = &quot;black&quot;) ggplot2::ggplot(data.frame(id=lcsm.proportional@Data@case.idx[[1]], lavPredict(lcsm.proportional,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;dlpfc&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% dplyr::mutate(wave = as.numeric(wave)), aes(x = wave, y = dlpfc, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Canonical Proportional LCSM Trajectories&quot;, x = &quot;Wave&quot;, y = &quot;Predicted DLFPC Activation&quot;) + theme(legend.position = &quot;none&quot;) "],["03-time.html", "Time Structure Assessment Schedules Time Coding Additional Considerations", " Time Structure Now that we have covered the basic forms of each of the four modeling frameworks, we can start thinking more deeply about how to include time in our longitudinal models. We will begin by visualizing different kinds of assessment schedules and how our models might change depending on the structure of our observations. We will read in subsets of datasets that appear elsewhere in this primer codebook that follow each of three exemplar assessment types. The single.cohort and accelerated datasets were drawn from the executive.function and feedback.learning datasets we saw in the canonical models chapter. The multiple.cohort dataset has been drawn from the adversity dataset (for details, see the Datasets chapter), which measures white matter development across 8 waves. These data contain fractional anisotropy (FA) measures derived from the forceps minor (fmin), a white matter tract that spans the hemispheres of the medial prefrontal cortex. We will see this dataset again when we consider predictors in the Covariates chapter. single.cohort &lt;- read.csv(&quot;data/single-cohort.csv&quot;, header = TRUE) multiple.cohort &lt;- read.csv(&quot;data/multiple-cohort.csv&quot;, header = TRUE) accelerated &lt;- read.csv(&quot;data/accelerated.csv&quot;, header = TRUE) Assessment Schedules Single Cohort Data As we cover in the main text, single cohort studies are by far the most common in longitudinal modeling. Below we can plot the assessment schedule for the canonical models we worked with in the last chapter. To declutter the plot, we have selected 50 individuals from the larger dataset and ordered them by their age at the first assessment. set.seed(12345) ggplot(single.cohort %&gt;% pivot_longer(cols=starts_with(&quot;age&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Age&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;) + theme(legend.position = &quot;top&quot;) We can see that there is some noise in the assessment schedule, as individuals are not observed at exactly intervals, however, we can see clear separation in ages between each wave. Because we cover this data extensively in the Canonical Models chapter, we will not show model fits here. However, we should note that because of the structure of this data, age and wave of assessment are highly collinear (and are more so the better job we do at observing individuals at regular intervals). This will impact our considerations about time later. Multiple Cohort Data A slightly more complex assessment schedule design is the multiple cohort design. In these designs, we have multiple, discrete ages at the first assessment which vary across cohorts. Here we can plot our multiple.cohort data, which is organized into three cohorts, beginning at ages \\(4\\), \\(5\\), and \\(6\\). While at later ages the cohorts mix somewhat in terms of ages sampled, no individual is observed at consecutive ages. This highlights a key advantage of the multiple cohort design; they can often provide coverage of a wider developmental window without requiring additional subjects or waves of assessment using principles of planned missingness. ggplot(multiple.cohort %&gt;% pivot_longer(cols=starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(....)(.+)&quot;) %&gt;% drop_na(fmin) %&gt;% mutate(age = as.numeric(age)), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(age), shape = factor(cohort)), size=2) + labs(x = &quot;Age&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) + guides(color = &quot;none&quot;) Here we will demonstrate how one might model this type of data using the linear latent curve model for simplicity; however, we could implement this model in any of the 4 modeling frameworks we discussed. To preface the model results, the values of the fmin outcome were normalized to the first age assessed (fmin4) because of the relatively small natural scale of FA values. We have also read in the full adversity data file due to convergence issues with the subsample in multiple.cohort. mc.wm.model &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 &quot; mc.wm &lt;- growth(mc.wm.model, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) The real leverage that FIML gives us is apparent using this model. We can measure across \\(8\\) ages despite no individual having more than \\(4\\) observations. We can see the abbreviated results below. summary(mc.wm, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 33 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 42.960 ## Degrees of freedom 31 ## P-value (Chi-square) 0.075 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## fmin4 1.000 0.656 ## fmin5 1.000 0.656 ## fmin6 1.000 0.656 ## fmin7 1.000 0.656 ## fmin8 1.000 0.656 ## fmin9 1.000 0.656 ## fmin10 1.000 0.656 ## fmin11 1.000 0.656 ## slp =~ ## fmin4 0.000 0.000 ## fmin5 1.000 0.125 ## fmin6 2.000 0.249 ## fmin7 3.000 0.374 ## fmin8 4.000 0.499 ## fmin9 5.000 0.623 ## fmin10 6.000 0.748 ## fmin11 7.000 0.872 ## Std.all ## ## 0.638 ## 0.685 ## 0.623 ## 0.582 ## 0.531 ## 0.535 ## 0.542 ## 0.480 ## ## 0.000 ## 0.130 ## 0.237 ## 0.331 ## 0.404 ## 0.508 ## 0.618 ## 0.638 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp 0.006 0.023 0.276 0.783 0.077 ## Std.all ## ## 0.077 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.000 0.000 ## .fmin5 0.000 0.000 ## .fmin6 0.000 0.000 ## .fmin7 0.000 0.000 ## .fmin8 0.000 0.000 ## .fmin9 0.000 0.000 ## .fmin10 0.000 0.000 ## .fmin11 0.000 0.000 ## int 0.026 0.053 0.485 0.628 0.039 ## slp 0.049 0.012 4.020 0.000 0.393 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.039 ## 0.393 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.627 0.141 4.440 0.000 0.627 ## .fmin5 0.458 0.102 4.475 0.000 0.458 ## .fmin6 0.591 0.105 5.646 0.000 0.591 ## .fmin7 0.664 0.091 7.315 0.000 0.664 ## .fmin8 0.796 0.125 6.389 0.000 0.796 ## .fmin9 0.621 0.095 6.565 0.000 0.621 ## .fmin10 0.398 0.116 3.438 0.001 0.398 ## .fmin11 0.589 0.125 4.694 0.000 0.589 ## int 0.431 0.117 3.690 0.000 1.000 ## slp 0.016 0.006 2.685 0.007 1.000 ## Std.all ## 0.593 ## 0.500 ## 0.533 ## 0.522 ## 0.522 ## 0.413 ## 0.272 ## 0.315 ## 1.000 ## 1.000 With this model, we will be warned that coverage for certain pairwise combinations is \\(&lt; 10\\%\\), which just reflects the fact that almost no individuals gave data at adjacent ages. We could inspect the model coverage using the lavInspect() function using the argument what = \"coverage\". Note the values at or near \\(0\\) on the 1-off diagonal (e.g., fmin5 and fmin4). lavInspect(mc.wm, what = &quot;coverage&quot;) ## fmin4 fmin5 fmin6 fmin7 fmin8 fmin9 fmin10 fmin11 ## fmin4 0.299 ## fmin5 0.000 0.420 ## fmin6 0.078 0.000 0.359 ## fmin7 0.209 0.264 0.000 0.472 ## fmin8 0.030 0.123 0.239 0.008 0.372 ## fmin9 0.196 0.204 0.070 0.342 0.003 0.430 ## fmin10 0.070 0.113 0.198 0.040 0.244 0.035 0.334 ## fmin11 0.151 0.239 0.055 0.342 0.040 0.359 0.030 0.430 Finally, we can generate a path diagram, highlighting that the intercept and slope are estimated from all ages even though no individual is measured across all of those ages. semPaths(mc.wm, intercepts = TRUE, edge.color = &quot;black&quot;) Accelerated Design The most complex assessment schedule is the accelerated longitudinal design, where no two individual are assessed at the same maturational state (usually age). While it isn’t strictly necessary that we have some smooth continuum of starting ages, accelerated longitudinal studies most often follow this approach. We can see an example below. set.seed(12345) ggplot(accelerated %&gt;% group_by(id) %&gt;% filter(length(unique(wave)) == 3) %&gt;% ungroup() %&gt;% filter(id %in% sample(id, 100)), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Age&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) Unlike the single or multiple-cohort data, where we have discrete timepoints of observations, here we have as many as three unique timepoints per person since individuals are unlikely to be the exact same age. While it is possible to fit this type of model using definition variables in an SEM (see the Mplus code for the TSCORE option), it is far more common to fit these assessment schedules with mixed effects models, where we can include precise age into the model as a continuous predictor. We can use the multilevel model to fit a quadratic growth curve to this data. Note that the linear and quadratic effects are fixed effects that are pooled across individuals, and that only the random intercept is included. We could include additional random effects if the data support them, although we would need sufficient numbers of observations within-person to do so. accel &lt;- lmer(scale(modularity) ~ 1 + age + I(age^2) + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) We can see the results of this model below. summary(accel) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: scale(modularity) ~ 1 + age + I(age^2) + (1 | id) ## Data: accelerated ## ## REML criterion at convergence: 642.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.02380 -0.55867 -0.00133 0.56810 2.43080 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.4079 0.6386 ## Residual 0.5131 0.7163 ## Number of obs: 243, groups: id, 81 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -4.229027 0.928266 239.194448 -4.556 8.32e-06 *** ## age 0.460537 0.105741 239.506334 4.355 1.97e-05 *** ## I(age^2) -0.011828 0.002949 238.656609 -4.011 8.10e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.982 ## I(age^2) 0.940 -0.986 If we want to get the overall fixed effects trend, rather than individual trajectories (as we did in the Canonical models), we can use the ggpredict() function from the ggeffects package to generate predicted values of the outcome at specific values of the predictor. This package is especially useful for generating ggplot-compatible dataframes when plotting interactions, but we can still use it for main effects (although a polynomial is a special form of an interaction). We can specify the levels of the predictor within the brackets ([]) or set them to all as we will here to get the full range of ages in our plot. We can then pass this dataframe to ggplot and plot the effect of age with confidence bands shaded. accel.effects = ggeffects::ggpredict(accel, terms=&#39;age [all]&#39;) ggplot(data=accel.effects, aes(x=x,y=predicted)) + geom_line() + geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha=.2) + labs(x=&#39;Age&#39;, y = &#39;Predicted Learning Rate&#39;) We can see quite a pronounced inverted-U quadratic effect here, with a peak around twenty. While we have this plot here, we might wish to know if the simple linear slope is significant at various points along the curve (i.e., is modularity significantly increasing or decreasing at a given age). To do so, we can use the simple_slopes() function from the interactions package. One quirk is that this function does not recognize a polynomial term like the one we have here. Instead, the function looks for separate variable labels. Well fortunately we can just trick it into working as we would like by duplicating the age variable under a new name (age_temp). We can then re-estimate our model with the interaction of age and our temporary age variable included (i.e., age:age_temp). accelerated &lt;- accelerated %&gt;% mutate(age_temp = age) probe.accel &lt;- lmer(scale(modularity) ~ 1 + age + age:age_temp + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) We can then pass the new model object to the simple_slopes() function with age as our focal predictor and age_temp as the moderator (of course in this case, it doesn’t matter which variable we put in which position). We can toggle the jnplot argument to TRUE in order to generate a plot of the linear effect of age as a function of age. This plot will show us where within the quadratic curve, we have significant increases or decreases, and where the linear effect is not significant. interactions::sim_slopes(probe.accel, pred = age, modx = age_temp, jnplot = TRUE, jnalpha = 0.05) ## JOHNSON-NEYMAN INTERVAL ## ## When age_temp is OUTSIDE the interval [18.79, 27.02], the slope ## of age is p &lt; .05. ## ## Note: The range of observed values of age_temp is [8.01, 28.46] ## SIMPLE SLOPES ANALYSIS ## ## Slope of age when age_temp = 13.14157 (- 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.10 0.02 4.40 0.00 ## ## Slope of age when age_temp = 17.17288 (Mean): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.05 0.02 3.01 0.00 ## ## Slope of age when age_temp = 21.20419 (+ 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.01 0.02 0.33 0.74 We can see that from around 19 to 27, the linear effect of age (i.e., the slope of the tangent line) is not significant but is significantly positive before and significantly negative after this age range. We round these numbers because we cannot really think we have such precise measurements to say that linear increases in modularity become non-significant exactly at 18.79. However, this sort of plot can help us distinguish between truly quadratic effects (within increases and decreases) versus a plateauing of the outcome at later ages. Time Coding One point of frequent confusion when modeling data (nevermind longitudinal models) is the role of centering the predictors for model results/fit/etc. In general, centering predictors does not change the fundamental information contained within the model, although sometimes it is necessary for practical reason (e.g., reducing collinearity between main effects and product terms). In longitudinal models, the main centering concern is where to place the intercept (i.e., where time is coded 0). While many of our parameter estimates will indeed change based on where we choose to estimate the intercept (most notably the…wait for it…intercept, as well as covariances with the intercept). Here we will demonstrate with the LCM framework since the factor-loading matrix makes what is happening very explicit, but you could replicate these results with any of the other approaches. First, we can fit the linear model to the single-cohort data we showed above. Here we will place the \\(0\\) factor loading at the first time point which will result in the intercept reflecting individual differences in the level of the outcome at the initial assessment (i.e., initial status). initial.status &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&quot; initial.status.fit &lt;- growth(initial.status, data = single.cohort, estimator = &quot;ML&quot;, missing=&quot;FIML&quot;) summary(initial.status.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 We will focus first on fit and then circle back to parameter estimates later. Here the chi-square test statistics is \\(12.14\\) on \\(5%\\) degrees of freedom (\\(p = 0.033\\)), the \\(CFI = 0.893\\) and the \\(RMSEA = 0.169\\). We can then re-estimate the model where we code the last factor loading as \\(0\\) instead so the intercept will represent final status. final.status &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ -3*dlpfc1 + -2*dlpfc2 + -1*dlpfc3 + 0*dlpfc4&quot; final.status.fit &lt;- growth(final.status, data = single.cohort, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(final.status.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 Looking at the model fit values, they are exactly identical to the initial status model. We have effectively re-arranged deck chairs on the Titanic (and Rose is about to shove Jack off that door; don’t @ me) as far as model fit goes. So why might we wish to reformulate this model? Well, individual differences in level might be interesting to interpret substantively at one point over another depending on our application of interest. While many research hypotheses will lend themselves naturally to the initial status approach, in intervention work or a training study we might be far more interesting in interpreting where individuals end up (spoken with all the authority of someone who does not do intervention work). Initial Status LCM Parameter Estimate SE Statistic p-value Std.LV Std.All dlpfc1 ~~ dlpfc1 0.280 0.196 1.427 0.154 0.280 0.307 dlpfc2 ~~ dlpfc2 0.459 0.140 3.275 0.001 0.459 0.435 dlpfc3 ~~ dlpfc3 0.389 0.128 3.039 0.002 0.389 0.368 dlpfc4 ~~ dlpfc4 0.640 0.278 2.302 0.021 0.640 0.428 int ~~ int 0.631 0.207 3.039 0.002 1.000 1.000 slp ~~ slp 0.055 0.054 1.010 0.313 1.000 1.000 int ~~ slp -0.045 0.097 -0.467 0.641 -0.243 -0.243 int ~1 0.628 0.132 4.761 0.000 0.791 0.791 slp ~1 0.114 0.054 2.120 0.034 0.487 0.487 Final Status LCM Parameter Estimate SE Statistic p-value Std.LV Std.All dlpfc1 ~~ dlpfc1 0.280 0.196 1.427 0.154 0.280 0.307 dlpfc2 ~~ dlpfc2 0.459 0.140 3.275 0.001 0.459 0.435 dlpfc3 ~~ dlpfc3 0.389 0.128 3.039 0.002 0.389 0.368 dlpfc4 ~~ dlpfc4 0.640 0.278 2.302 0.021 0.640 0.428 int ~~ int 0.853 0.262 3.262 0.001 1.000 1.000 slp ~~ slp 0.055 0.054 1.010 0.313 1.000 1.000 int ~~ slp 0.119 0.093 1.284 0.199 0.552 0.552 int ~1 0.970 0.158 6.124 0.000 1.050 1.050 slp ~1 0.114 0.054 2.120 0.034 0.487 0.487 We can see that some parameters won’t change based on the time-coding. For instance, the residual variances of the repeated measures (and therefore the R-squares), and the mean and variance of the slope factor. However, the mean and variance of the intercept changes, as does the correlation between the slope and intercept (initial status: \\(r = -0.243\\); final status: \\(r = 0.552\\)). Note that the sign of the correlation flips and the magnitude of the difference is quite substantial. This should urge caution not to interpret the intercept outside of the specific timepoint it is estimated for since it’s parameter values will be context specific (due to rank-order shifts due to random slopes). If we wanted to use a mixed effect model, we might be better off just transforming our predictor variable to reflect the code we want. We can transform the single.cohort data below to suit our purposes. single.cohort.long &lt;- single.cohort %&gt;% pivot_longer(cols=starts_with(c(&quot;age&quot;, &quot;dlpfc&quot;)), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% mutate(wave = as.numeric(wave), age_initial = age - min(age, na.rm = TRUE), age_final = age - max(age, na.rm = TRUE)) We can then fit the models as we usually do to see the equivalencies. initial.status.mlm &lt;- lmer(dlpfc ~ 1 + age_initial + (1 + age_initial | id), na.action = na.omit, REML = TRUE, data = single.cohort.long) final.status.mlm &lt;- lmer(dlpfc ~ 1 + age_final + (1 + age_final | id), na.action = na.omit, REML = TRUE, data = single.cohort.long) tab_model(initial.status.mlm, final.status.mlm, show.se = TRUE, show.df = FALSE, show.ci = FALSE, digits = 3, pred.labels = c(&quot;Intercept&quot;, &quot;Age - min(Age)&quot;, &quot;Age - max(Age)&quot;), dv.labels = c(&quot;Initial Status&quot;, &quot;Final Status&quot;), string.se = &quot;SE&quot;, string.p = &quot;P-Value&quot;)   Initial Status Final Status Predictors Estimates SE P-Value Estimates SE P-Value Intercept 0.619 0.145 &lt;0.001 0.984 0.166 &lt;0.001 Age - min(Age) 0.106 0.056 0.062 Age - max(Age) 0.106 0.056 0.062 Random Effects σ2 0.43 0.43 τ00 0.66 id 0.98 id τ11 0.07 id.age_initial 0.07 id.age_final ρ01 -0.33 id 0.63 id ICC 0.62 0.62 N 50 id 50 id Observations 191 191 Marginal R2 / Conditional R2 0.012 / 0.624 0.012 / 0.624 Note that the slope estimates are identical, while estimates involving the intercept change as we saw before. Additional Considerations One thing that has been consistent across all the models that we have fit thus far is that they are structured primarily by the chronological age of the individuals in question. Even when we have used wave of assessment as the nominal variable encoding time, waves have been spaced into yearly assessments and the lack of heterogeneity in ages collapses age and wave (either in reality or in practice when we fix factor loadings). However, nothing stops us from structuring the repeated measures by some other metric of maturation, practice, or anything else (except for pesky things like convention and serious measurement/modeling challenges, but that’s all). For instance, we could plot our repeated measures in the accelerated data again, but instead of chronological age, we could put pubertal status (measured by Tanner stage) on the x-axis. That would result in the plot below. Alternative Metrics of Time ggplot(accelerated, aes(x = puberty, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Tanner Stage&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) In some ways, this roughly resembles the age plot, with some individuals being measured at earlier stages of puberty and other later. However, close inspection starts to uncover some issues. First, we often stop measuring puberty once individual reach a certain age/stage of development, so puberty as a measure of maturation is limited in it’s utility outside of a fairly specific phase of development. We can already see for subjects who are measured first at later ages having missing data for later observations because puberty measures were not taken. There is also the curious case that some subset of individuals seem to move backwards in pubertal development (this should be treated as an error, but it’s amusing nonetheless). However, the key feature of interest in a plot like this is that, unlike age, there is not reason to expect that all individuals “age” at the same rate across puberty, seen by the uneven spacing between waves within individuals. This variation is just one of the exciting opportunities that modeling maturation using metric other than age present (although they do come with their own challenges; there is an admittedly understandable reason that age is the predominate variable in longitudinal models). One other advantage is within-age heterogeneity, which we can see by plotting Tanner Stage by age in the plot below. ggplot(accelerated, aes(x = age, y = puberty)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Age&quot;, y = &quot;Tanner Stage&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) We can see that same-age peers may differ considerable (depending on when we measure them) in their pubertal development. We can also fit puberty-related trajectories to the modularity data below. accel &lt;- lmer(scale(modularity) ~ 1 + puberty + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) summary(accel, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: scale(modularity) ~ 1 + puberty + (1 | id) ## Data: accelerated ## ## REML criterion at convergence: 417.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.49262 -0.65415 0.04191 0.58260 2.43878 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.3322 0.5763 ## Residual 0.6698 0.8184 ## Number of obs: 150, groups: id, 67 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.96653 0.28495 133.98649 -3.392 0.000913 *** ## puberty 0.34156 0.09681 145.04845 3.528 0.000561 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Of course, we might wish to model age and puberty simultaneously. That may present practical challenges in this data, since age and puberty are highly correlated \\(r = 0.796\\), but some strategies for modeling multiple growth processes have been suggested elsewhere (see the relevant portion of the main text for details). Residual Estimates The final consideration we will explore in our discussion of time is the structure of the residuals of our repeated measures. This is often not of great theoretical importance (I don’t really believe you if you tell me your theory is specific enough to know if residual variance should be constant or not…call me a grinch), but it can be really important for model results. Essentially, an overly restrictive assumption about residual variances at the individual observation level can radiate out into the random effects structure and bias your effects. Here we will show how to specify both forms of a model in a mixed effect and structural equation model, and test which one is a better fit to the data. We can start with the LCM, where heteroscedasticity (i.e., unique residual estimates across) is the default. To obtain this model, we use the same syntax we have seen repeatedly so far. lcm.het &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&quot; lcm.het.fit &lt;- growth(lcm.het, data = single.cohort, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcm.het.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.045 0.097 -0.467 0.641 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.628 0.132 4.761 0.000 ## slp 0.114 0.054 2.120 0.034 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.280 0.196 1.427 0.154 ## .dlpfc2 0.459 0.140 3.275 0.001 ## .dlpfc3 0.389 0.128 3.039 0.002 ## .dlpfc4 0.640 0.278 2.302 0.021 ## int 0.631 0.207 3.039 0.002 ## slp 0.055 0.054 1.010 0.313 We can easily see that each residual obtains a unique value with an associated inference test (.dlpfc1 - .dlpfc4). To constrain these residuals equal across time, we have to explicitly write out the residual term (we have been relying on sensible defaults thus far) and then pre-multiply each estimate by the same alpha-numeric label. Lavaan will interpret repeated labels as a request for an equality constraint on those parameters. We can see this constraint in action below. lcm.hom &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 dlpfc1 ~~ c1*dlpfc1 dlpfc2 ~~ c1*dlpfc2 dlpfc3 ~~ c1*dlpfc3 dlpfc4 ~~ c1*dlpfc4&quot; The choice of constraint (here c1) is somewhat arbitrary, but the point is that it can contain characters and numbers (although it must begin with a character). When we fit the model, we will see those parameters will be held equal. lcm.hom.fit &lt;- growth(lcm.hom, data = single.cohort, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcm.hom.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 19 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## Number of equality constraints 3 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 14.724 ## Degrees of freedom 8 ## P-value (Chi-square) 0.065 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.041 0.061 -0.668 0.504 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.640 0.134 4.761 0.000 ## slp 0.108 0.055 1.969 0.049 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 (c1) 0.435 0.065 6.732 0.000 ## .dlpfc2 (c1) 0.435 0.065 6.732 0.000 ## .dlpfc3 (c1) 0.435 0.065 6.732 0.000 ## .dlpfc4 (c1) 0.435 0.065 6.732 0.000 ## int 0.590 0.189 3.129 0.002 ## slp 0.059 0.032 1.838 0.066 Lavaan conveniently includes the labels in the output and we can see that now all of the residuals obtain the exact same value, and exact same inferential test (note how that changes the inference on the residual of dlpfc1 from above). However, note how other parameter estimates (namely the factor means and variances) change as well. These changes are small (for reasons we will see) but it is important to note we are making real changes to the model with the introduction of this constraint. We can then get a likelihood-ratio test of difference in fit, using the lavTestLRT() function, because the simplified homoscedastic model is nested within the more complex heteroscedastic model. Note that we list the homoscedastic model first. lavaan::lavTestLRT(lcm.hom.fit, lcm.het.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## lcm.het.fit 5 514.35 531.56 12.140 ## lcm.hom.fit 8 510.93 522.40 14.724 2.5837 3 0.4604 However, in the output, the heteroscedastic model is listed first. This is because the more complex model is always the reference and we are testing whether the imposition of model simplifications (i.e., constraints; here homoscedastic residuals) significantly decreases model fit. Here we can see that the chi-square difference test is not significant (\\(p = 0.460\\)), so we could retain the simplification without decreasing the fit of the model to our data. This is the reason that our parameters did not change much. In models where we would reject homoscedasticity, the imposition of the constraint would lead to more pronounced parameter changes elsewhere in the model. While there is not an associated inference test for the AIC/BIC, we could also use those values for model comparisons if we wished. To implement heteroscedastic residuals in mixed-effects models, we have to leave our familiar lmer() and travel back in time to the days of lme(). We can first fit the canonical model we know and love, where the default is homoscedasticity. mlm.hom &lt;- nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, na.action = na.omit, method = &quot;REML&quot;, data = single.cohort.long) summary(mlm.hom, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: single.cohort.long ## AIC BIC logLik ## 517.3124 536.7629 -252.6562 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8717474 (Intr) ## wave 0.2500535 -0.489 ## Residual 0.6595289 ## ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5321058 0.16886967 140 3.150985 0.0020 ## wave 0.1076007 0.05524678 140 1.947638 0.0535 ## Correlation: ## (Intr) ## wave -0.705 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.09037990 -0.49924910 -0.04034052 0.65971936 2.07352349 ## ## Number of Observations: 191 ## Number of Groups: 50 Note that in the Random effects portion of the output, we obtain a single numerical value for the residual \\(\\sigma^2 = 0.660\\). To fit a heteroscedastic model, we need to make use of a new argument, weights. We can specify the form argument of the varIdent() (“variance identity) function to obtain a unique estimate per wave. mlm.het &lt;- nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, weights = varIdent(form = ~ 1 | wave), na.action = na.omit, method = &quot;REML&quot;, data = single.cohort.long) summary(mlm.het, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: single.cohort.long ## AIC BIC logLik ## 520.7754 549.9511 -251.3877 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8975009 (Intr) ## wave 0.2413003 -0.495 ## Residual 0.5269518 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | wave ## Parameter estimates: ## 1 2 3 4 ## 1.000000 1.287069 1.184203 1.515231 ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5144231 0.16258045 140 3.164114 0.0019 ## wave 0.1139612 0.05386346 140 2.115743 0.0361 ## Correlation: ## (Intr) ## wave -0.675 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.09852285 -0.47236320 -0.01588848 0.64203216 2.12263672 ## ## Number of Observations: 191 ## Number of Groups: 50 Looking at the Random effects output, we still only see a single value for the residual. Unfortunately the output structure here leaves something to be desired. We need to look to the Variance function output section where we see for unique values. Well these are not technically the residual estimates, but rather they indicate the relative size of the residual scaled to the first estimate (the one we see in the Random effects section). To extract the actual estimates, we can use the following code. mlm.het$sigma * exp(as.numeric(mlm.het$modelStruct$varStruct)) ## [1] 0.6782232 0.6240178 0.7984535 So the first residual can be extracted as model$sigma, but the residual weights from the model are stuck in the varStruct portion of the fitted lme() object and are in the \\(log(\\sigma)\\) scale. So we have to extract the values, convert them to numeric format, exponentiate them, and then multiple the weights by the estimated residual to obtain the other three estimates (tired yet?). Fortunately, model comparisons are straightforward with the anova() function, which we can use in the same way we used lavTestLRT() to compare LCMs early. anova(mlm.het, mlm.hom) ## Model df AIC BIC logLik Test L.Ratio p-value ## mlm.het 1 9 520.7754 549.9511 -251.3877 ## mlm.hom 2 6 517.3124 536.7629 -252.6562 1 vs 2 2.537015 0.4686 Like before, these results indicate that imposing homoscedasticity does not significantly decrease model fit. "],["04-shape.html", "The Shape of Development Polynomial Trajectories Piecewise Trajectories Nonlinear Trajectories Additional Considerations", " The Shape of Development However, we define the underlying metric of time to structure our longitudinal model, one of the key substantive questions often underlying work in developmental science is to characterize the course that a given construct takes over time. Here we will highlight many of the different developmental trajectories that we can fit to our data, starting with relatively simple polynomial shapes and working our way up to modeling fully nonlinear trends. In addition to the feedback.learning data we have used thus far, we will also use data drawn from the external-math.csv and adversity.csv files. The external.math data contains up to \\(5\\) repeated observations from \\(405\\) children aged \\(6\\) to \\(14\\), measured once every \\(2\\) years. Here we will focus on measures of externalizing behavior and math proficiency. The adversity data contains fractional anisotropy (FA) measures from \\(398\\) children measured up to \\(4\\) times across ages \\(4\\) to \\(11\\). We previously used a subset of this data in the Time chapter, but here we will utilize the entire sample. external.math &lt;- read.csv(&quot;data/external-math.csv&quot;) adversity &lt;- read.csv(&quot;data/adversity.csv&quot;) feedback.learning &lt;- read.csv(&quot;data/feedback-learning.csv&quot;) %&gt;% select(id, age, modularity, learning.rate) Polynomial Trajectories Like we discussed in the main text, polynomial trajectories are far and away the most common trajectories modeled with longitudinal data. They require relatively few unique timepoints, are straightforward to model, and offer easily-interpretable parameter estimates. Intercept-Only Model We can first consider the simplest polynomial model, one without even a slope. The intercept-only model simply models person-specific differences in average level across time. We can start here with the LCM, which makes the various specifications easiest to see, but we will also build syntax for models in the other frameworks. int.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14&quot; int.lcm.fit &lt;- growth(int.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(int.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 7 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 71.246 ## Degrees of freedom 13 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ext6 1.000 ## ext8 1.000 ## ext10 1.000 ## ext12 1.000 ## ext14 1.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 0.000 ## .ext8 0.000 ## .ext10 0.000 ## .ext12 0.000 ## .ext14 0.000 ## int 1.882 0.077 24.397 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 1.761 0.203 8.690 0.000 ## .ext8 1.771 0.189 9.384 0.000 ## .ext10 2.023 0.208 9.730 0.000 ## .ext12 2.243 0.230 9.758 0.000 ## .ext14 2.049 0.348 5.891 0.000 ## int 1.752 0.172 10.161 0.000 We can see that there is significant variance in the intercept factor, suggesting meaningful person-to-person variability in level of externalizing behavior during late childhood and early adolescence. While this might seem a somewhat silly model to fit to these data, this is one half of a random-intercept cross-lag panel model and might be appropriate if we do not expect systematic change over time. However, these intercept-only models are admittedly more plausible for intensive longitudinal data. The MLM specification for this model can be seen below. We will first transform the data into long format before fitting the model. external.math.long &lt;- external.math %&gt;% pivot_longer(cols = starts_with(c(&quot;ext&quot;, &quot;math&quot;)), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(ext|math)(.+)&quot;) %&gt;% mutate(age = as.numeric(age)) int.mlm &lt;- lmer(ext ~ 1 + (1 | id), na.action = na.omit, REML = TRUE, data = external.math.long) summary(int.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: ext ~ 1 + (1 | id) ## Data: external.math.long ## ## REML criterion at convergence: 5316.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2539 -0.5600 -0.2063 0.4736 4.5276 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 1.799 1.341 ## Residual 1.944 1.394 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.89455 0.07736 399.24978 24.49 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that this is just a random-effects ANOVA model with no predictors. Linear Model We will move quickly through the linear polynomial models because we have covered them extensively thus far. Below is the syntax for the linear LCM. Remember that assessments are biannual so factor loadings should increase by two for each wave. lin.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14&quot; lin.lcm.fit &lt;- growth(lin.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lin.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 19.507 ## Degrees of freedom 10 ## P-value (Chi-square) 0.034 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ext6 1.000 ## ext8 1.000 ## ext10 1.000 ## ext12 1.000 ## ext14 1.000 ## slp =~ ## ext6 0.000 ## ext8 2.000 ## ext10 4.000 ## ext12 6.000 ## ext14 8.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp 0.084 0.042 2.003 0.045 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 0.000 ## .ext8 0.000 ## .ext10 0.000 ## .ext12 0.000 ## .ext14 0.000 ## int 1.664 0.081 20.459 0.000 ## slp 0.074 0.018 4.135 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 1.653 0.239 6.914 0.000 ## .ext8 1.844 0.188 9.807 0.000 ## .ext10 1.910 0.199 9.593 0.000 ## .ext12 1.592 0.227 7.007 0.000 ## .ext14 1.618 0.372 4.346 0.000 ## int 1.068 0.227 4.710 0.000 ## slp 0.024 0.011 2.066 0.039 While we have ignored model fit for most models, one nice thing about many of these models, is that they are nested and allow for formal model comparison with likelihood ratio tests, similar to those we saw with hetero- vs. homoscedastic residuals. For instance, we can compare the intercept-only with a linear model. lavTestLRT(int.lcm.fit, lin.lcm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## lin.lcm.fit 10 5278.2 5318.3 19.506 ## int.lcm.fit 13 5324.0 5352.0 71.246 51.74 3 3.403e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Remember that we compare whether the more constrained model (here the intercept-only) induces a significant decrease in model fit. Here this is true, suggesting that we should retain the linear model over the intercept-only model. If we take a peak at the model fit, this is because the linear model fits the data reasonably well, while the intercept-only model is quite poor in terms of fit. summary(int.lcm.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 7 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 71.246 ## Degrees of freedom 13 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 361.048 ## Degrees of freedom 10 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.834 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2654.990 ## Loglikelihood unrestricted model (H1) -2619.367 ## ## Akaike (AIC) 5323.980 ## Bayesian (BIC) 5352.007 ## Sample-size adjusted Bayesian (BIC) 5329.795 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.105 ## 90 Percent confidence interval - lower 0.082 ## 90 Percent confidence interval - upper 0.130 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.156 summary(lin.lcm.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 19.507 ## Degrees of freedom 10 ## P-value (Chi-square) 0.034 ## ## Model Test Baseline Model: ## ## Test statistic 361.048 ## Degrees of freedom 10 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.973 ## Tucker-Lewis Index (TLI) 0.973 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2629.120 ## Loglikelihood unrestricted model (H1) -2619.367 ## ## Akaike (AIC) 5278.240 ## Bayesian (BIC) 5318.279 ## Sample-size adjusted Bayesian (BIC) 5286.547 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.048 ## 90 Percent confidence interval - lower 0.013 ## 90 Percent confidence interval - upper 0.080 ## P-value RMSEA &lt;= 0.05 0.486 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.082 To fit the corresponding MLM, we first need to generate our linear predictor as an observed variable in our data frame (and will need to do so each time we increase the order of the model). Here we will generate the linear predictor by simply subtracting \\(6\\) from the age variable. external.math.long$age &lt;- external.math.long$age - min(external.math.long$age) lin.mlm &lt;- lmer(ext ~ 1 + age + (1 + age | id), na.action = na.omit, REML = TRUE, data = external.math.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(lin.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: ext ~ 1 + age + (1 + age | id) ## Data: external.math.long ## Control: ## lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 5269.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1375 -0.5422 -0.1737 0.4491 3.9389 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 1.02975 1.0148 ## age 0.01778 0.1334 0.75 ## Residual 1.78241 1.3351 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.66939 0.08114 372.83468 20.574 &lt; 2e-16 *** ## age 0.07235 0.01758 288.52536 4.116 5.03e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 And the model comparison reveals the same preference for the linear model. Note that the model is re-estimated with ML [FIML] because the two models contain different fixed effects. REML models can be compared when the models differ only in the variance structure. Fortunately this will be done automatically so we don’t have to “manually” re-estimate the models. anova(int.mlm, lin.mlm) ## Data: external.math.long ## Models: ## int.mlm: ext ~ 1 + (1 | id) ## lin.mlm: ext ~ 1 + age + (1 + age | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## int.mlm 3 5319.5 5335.1 -2656.7 5313.5 ## lin.mlm 6 5271.7 5303.0 -2629.9 5259.7 53.736 3 1.277e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Finally, we can see a version of the linear LCSM for the external.math data below. Note again that biannual observations mean that we need to set the factor loadings for the slope factor to \\(2\\) instead of \\(1\\) to indicate the spacing appropriately. lin.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pext6 =~ 1*ext6; ext6 ~ 0; ext6 ~~ ext6; pext6 ~~ 0*pext6 pext8 =~ 1*ext8; ext8 ~ 0; ext8 ~~ ext8; pext8 ~~ 0*pext8 pext10 =~ 1*ext10; ext10 ~ 0; ext10 ~~ ext10; pext10 ~~ 0*pext10 pext12 =~ 1*ext12; ext12 ~ 0; ext12 ~~ ext12; pext12 ~~ 0*pext12 pext14 =~ 1*ext14; ext14 ~ 0; ext14 ~~ ext14; pext14 ~~ 0*pext14 # Regressions Between Adjacent Observations pext8 ~ 1*pext6 pext10 ~ 1*pext8 pext12 ~ 1*pext10 pext14 ~ 1*pext12 # Define Change Latent Variables (delta) delta21 =~ 1*pext8; delta21 ~~ 0*delta21 delta32 =~ 1*pext10; delta32 ~~ 0*delta32 delta43 =~ 1*pext12; delta43 ~~ 0*delta43 delta54 =~ 1*pext14; delta54 ~~ 0*delta54 # Define Intercept and Slope int =~ 1*pext6 slp =~ 2*delta21 + 2*delta32 + 2*delta43 + 2*delta54 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; lin.lcsm.fit &lt;- sem(lin.lcsm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lin.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 19.507 ## Degrees of freedom 10 ## P-value (Chi-square) 0.034 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## pext6 =~ ## ext6 1.000 ## pext8 =~ ## ext8 1.000 ## pext10 =~ ## ext10 1.000 ## pext12 =~ ## ext12 1.000 ## pext14 =~ ## ext14 1.000 ## delta21 =~ ## pext8 1.000 ## delta32 =~ ## pext10 1.000 ## delta43 =~ ## pext12 1.000 ## delta54 =~ ## pext14 1.000 ## int =~ ## pext6 1.000 ## slp =~ ## delta21 2.000 ## delta32 2.000 ## delta43 2.000 ## delta54 2.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## pext8 ~ ## pext6 1.000 ## pext10 ~ ## pext8 1.000 ## pext12 ~ ## pext10 1.000 ## pext14 ~ ## pext12 1.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp 0.084 0.042 2.003 0.045 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 0.000 ## .ext8 0.000 ## .ext10 0.000 ## .ext12 0.000 ## .ext14 0.000 ## int 1.664 0.081 20.459 0.000 ## slp 0.074 0.018 4.135 0.000 ## .pext6 0.000 ## .pext8 0.000 ## .pext10 0.000 ## .pext12 0.000 ## .pext14 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## .delta54 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 1.653 0.239 6.914 0.000 ## .pext6 0.000 ## .ext8 1.844 0.188 9.807 0.000 ## .pext8 0.000 ## .ext10 1.910 0.199 9.593 0.000 ## .pext10 0.000 ## .ext12 1.592 0.227 7.007 0.000 ## .pext12 0.000 ## .ext14 1.618 0.372 4.346 0.000 ## .pext14 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## .delta54 0.000 ## slp 0.024 0.011 2.066 0.039 ## int 1.068 0.227 4.710 0.000 Quadratic Model Next, we can add an additional factor to capture quadratic curvature in our data. Below is the LCM syntax for this model. Note that this is an extremely straightforward expansion of the syntax we have seen thus far. While this won’t be the case here, sometimes we need to worry about numerically large factor loadings causing some estimation issues in practice (nothing theoretical is wrong with large factor loadings). In those instances, we could divide our factor loadings by some constant to control those values from getting to large (although this will change the interpretation of a per-unit change). quad.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14 quad =~ 0*ext6 + 4*ext8 + 16*ext10 + 36*ext12 + 64*ext14&quot; quad.lcm.fit &lt;- growth(quad.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(quad.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 95 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.437 ## Degrees of freedom 6 ## P-value (Chi-square) 0.489 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## ext6 1.000 1.166 ## ext8 1.000 1.166 ## ext10 1.000 1.166 ## ext12 1.000 1.166 ## ext14 1.000 1.166 ## slp =~ ## ext6 0.000 0.000 ## ext8 2.000 1.040 ## ext10 4.000 2.079 ## ext12 6.000 3.119 ## ext14 8.000 4.159 ## quad =~ ## ext6 0.000 0.000 ## ext8 4.000 0.228 ## ext10 16.000 0.912 ## ext12 36.000 2.051 ## ext14 64.000 3.647 ## Std.all ## ## 0.731 ## 0.625 ## 0.566 ## 0.546 ## 0.551 ## ## 0.000 ## 0.558 ## 1.010 ## 1.461 ## 1.964 ## ## 0.000 ## 0.122 ## 0.443 ## 0.961 ## 1.722 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp -0.108 0.209 -0.514 0.607 -0.177 ## quad 0.018 0.023 0.772 0.440 0.270 ## slp ~~ ## quad -0.029 0.015 -1.933 0.053 -0.970 ## Std.all ## ## -0.177 ## 0.270 ## ## -0.970 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 0.000 0.000 ## .ext8 0.000 0.000 ## .ext10 0.000 0.000 ## .ext12 0.000 0.000 ## .ext14 0.000 0.000 ## int 1.567 0.088 17.809 0.000 1.344 ## slp 0.182 0.051 3.535 0.000 0.349 ## quad -0.015 0.007 -2.300 0.021 -0.271 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.344 ## 0.349 ## -0.271 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 1.188 0.431 2.758 0.006 1.188 ## .ext8 1.731 0.191 9.076 0.000 1.731 ## .ext10 1.691 0.215 7.858 0.000 1.691 ## .ext12 1.672 0.227 7.379 0.000 1.672 ## .ext14 1.381 0.649 2.128 0.033 1.381 ## int 1.360 0.431 3.159 0.002 1.000 ## slp 0.270 0.124 2.175 0.030 1.000 ## quad 0.003 0.002 1.705 0.088 1.000 ## Std.all ## 0.466 ## 0.498 ## 0.399 ## 0.367 ## 0.308 ## 1.000 ## 1.000 ## 1.000 lavTestLRT(lin.lcm.fit, quad.lcm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## quad.lcm.fit 6 5272.2 5328.2 5.4373 ## lin.lcm.fit 10 5278.2 5318.3 19.5065 14.069 4 0.007077 ## ## quad.lcm.fit ## lin.lcm.fit ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The MLM syntax is similarly straightforward. To add a powered term, we can use the I() function, or the poly() function if we wished to use orthogonal polynomials. quad.mlm &lt;- lmer(ext ~ 1 + age + I(age^2) + (1 + age + I(age^2) | id), na.action = na.omit, REML = TRUE, data = external.math.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(quad.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: ext ~ 1 + age + I(age^2) + (1 + age + I(age^2) | id) ## Data: external.math.long ## Control: ## lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 5263.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2948 -0.5378 -0.1802 0.4328 4.1605 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.942787 0.97097 ## age 0.162793 0.40348 0.27 ## I(age^2) 0.001871 0.04325 -0.12 -0.96 ## Residual 1.684821 1.29801 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.574442 0.087961 345.809227 17.899 &lt; 2e-16 *** ## age 0.178331 0.051186 357.020201 3.484 0.000555 *** ## I(age^2) -0.015107 0.006678 299.946299 -2.262 0.024398 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 While these models converge without too much issue here, note the strong correlation between the linear and quadratic terms, suggesting that the quadratic term is largely redundant. This is often the case with low numbers of repeated measures. We can technically fit some non-linearities, but they may not be particularly well-specified. The LCSM syntax requires a bit more explanation. The quadratic model is shown below. quad.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pext6 =~ 1*ext6; ext6 ~ 0; ext6 ~~ ext6; pext6 ~~ 0*pext6 pext8 =~ 1*ext8; ext8 ~ 0; ext8 ~~ ext8; pext8 ~~ 0*pext8 pext10 =~ 1*ext10; ext10 ~ 0; ext10 ~~ ext10; pext10 ~~ 0*pext10 pext12 =~ 1*ext12; ext12 ~ 0; ext12 ~~ ext12; pext12 ~~ 0*pext12 pext14 =~ 1*ext14; ext14 ~ 0; ext14 ~~ ext14; pext14 ~~ 0*pext14 # Regressions Between Adjacent Observations pext8 ~ 1*pext6 pext10 ~ 1*pext8 pext12 ~ 1*pext10 pext14 ~ 1*pext12 # Define Change Latent Variables (delta) delta21 =~ 1*pext8; delta21 ~~ 0*delta21 delta32 =~ 1*pext10; delta32 ~~ 0*delta32 delta43 =~ 1*pext12; delta43 ~~ 0*delta43 delta54 =~ 1*pext14; delta54 ~~ 0*delta54 # Define Intercept and Slope int =~ 1*pext6 slp =~ 2*delta21 + 2*delta32 + 2*delta43 + 2*delta54 quad =~ 4*delta21 + 12*delta32 + 20*delta43 + 28*delta54 int ~ 1 slp ~ 1 quad ~ 1 int ~~ slp int ~~ quad slp ~~ slp slp ~~ quad quad ~~ quad &quot; We talked in the Canonical chapter about how the loadings for the linear factor were all \\(1\\), and this could be thought of as summing across the difference factors. Another way to think of this specification is that the factor loadings for the LCSM are the differences between successive loadings for the LCM. In the standard linear case, these are all \\(1\\)s to indicate a constant effect across units of time, whereas in our example in this chapter, they are all differences of \\(2\\) to reflect biannual observations. The same principle can be applied to the loadings for higher-order factors in the LCSM. For a quadratic factor, the LCM loadings are [\\(0\\), \\(4\\), \\(16\\), \\(36\\), \\(64\\)], and therefore the LCSM loadings should be [(\\(4 - 0\\)), (\\(16 - 4\\)), (\\(36 - 16\\)), (\\(64 - 36\\))] = [\\(4\\), \\(12\\), \\(20\\), \\(28\\)]. As a sanity check, we can fit this model and the parameter estimates should match the LCM results exactly. quad.lcsm.fit &lt;- sem(quad.lcsm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(quad.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 95 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.437 ## Degrees of freedom 6 ## P-value (Chi-square) 0.489 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pext6 =~ ## ext6 1.000 1.166 ## pext8 =~ ## ext8 1.000 1.322 ## pext10 =~ ## ext10 1.000 1.597 ## pext12 =~ ## ext12 1.000 1.698 ## pext14 =~ ## ext14 1.000 1.761 ## delta21 =~ ## pext8 1.000 0.621 ## delta32 =~ ## pext10 1.000 0.257 ## delta43 =~ ## pext12 1.000 0.167 ## delta54 =~ ## pext14 1.000 0.362 ## int =~ ## pext6 1.000 1.000 ## slp =~ ## delta21 2.000 1.267 ## delta32 2.000 2.529 ## delta43 2.000 3.665 ## delta54 2.000 1.629 ## quad =~ ## delta21 4.000 0.278 ## delta32 12.000 1.663 ## delta43 20.000 4.017 ## delta54 28.000 2.499 ## Std.all ## ## 0.731 ## ## 0.709 ## ## 0.775 ## ## 0.796 ## ## 0.832 ## ## 0.621 ## ## 0.257 ## ## 0.167 ## ## 0.362 ## ## 1.000 ## ## 1.267 ## 2.529 ## 3.665 ## 1.629 ## ## 0.278 ## 1.663 ## 4.017 ## 2.499 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pext8 ~ ## pext6 1.000 0.882 ## pext10 ~ ## pext8 1.000 0.828 ## pext12 ~ ## pext10 1.000 0.941 ## pext14 ~ ## pext12 1.000 0.964 ## Std.all ## ## 0.882 ## ## 0.828 ## ## 0.941 ## ## 0.964 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp -0.108 0.209 -0.514 0.607 -0.177 ## quad 0.018 0.023 0.772 0.440 0.270 ## slp ~~ ## quad -0.029 0.015 -1.933 0.053 -0.970 ## Std.all ## ## -0.177 ## 0.270 ## ## -0.970 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 0.000 0.000 ## .ext8 0.000 0.000 ## .ext10 0.000 0.000 ## .ext12 0.000 0.000 ## .ext14 0.000 0.000 ## int 1.567 0.088 17.809 0.000 1.344 ## slp 0.182 0.051 3.535 0.000 0.349 ## quad -0.015 0.007 -2.300 0.021 -0.271 ## .pext6 0.000 0.000 ## .pext8 0.000 0.000 ## .pext10 0.000 0.000 ## .pext12 0.000 0.000 ## .pext14 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 0.000 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.344 ## 0.349 ## -0.271 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 1.188 0.431 2.758 0.006 1.188 ## .pext6 0.000 0.000 ## .ext8 1.731 0.191 9.076 0.000 1.731 ## .pext8 0.000 0.000 ## .ext10 1.691 0.215 7.858 0.000 1.691 ## .pext10 0.000 0.000 ## .ext12 1.672 0.227 7.379 0.000 1.672 ## .pext12 0.000 0.000 ## .ext14 1.381 0.649 2.128 0.033 1.381 ## .pext14 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 0.000 ## slp 0.270 0.124 2.175 0.030 1.000 ## quad 0.003 0.002 1.705 0.088 1.000 ## int 1.360 0.431 3.159 0.002 1.000 ## Std.all ## 0.466 ## 0.000 ## 0.498 ## 0.000 ## 0.399 ## 0.000 ## 0.367 ## 0.000 ## 0.308 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.000 ## 1.000 ## 1.000 lavTestLRT(lin.lcsm.fit, quad.lcsm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## quad.lcsm.fit 6 5272.2 5328.2 5.4373 ## lin.lcsm.fit 10 5278.2 5318.3 19.5065 14.069 4 0.007077 ## ## quad.lcsm.fit ## lin.lcsm.fit ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Inverse Model The final polynomial model we will consider is the inverse model. Unlike the quadratic curvature which reverses, the inverse curve approaches a plateau asymptotically. We can do a quick algebraic transformation to make the factor loadings tractable by inverting the original (i.e., not centered) values and subtracting them from \\(1\\). So for linear loadings [\\(1\\), \\(3\\), \\(5\\), \\(7\\), \\(9\\)], we would have inverse factor loadings [\\(1 - (1/1)\\), \\(1 - (1/3)\\), \\(1 - (1/5)\\), \\(1 - (1/7)\\), \\(1 - (1/9)\\)] or [\\(0\\), \\(2/3\\), \\(4/5\\), \\(6/7\\), \\(8/9\\)]. Inverting the original loadings avoids trying to take the reciprocal of 0 (which results in 6 more weeks of COVID variants) and subtracting from one specifies an upper rather than lower bound effect (this won’t change the nature of the effect, it just makes the sign easier to interpret). inv.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14 inv =~ 0*ext6 + (2/3)*ext8 + (4/5)*ext10 + (6/7)*ext12 + (7/8)*ext14&quot; inv.lcm.fit &lt;- growth(inv.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(inv.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 64 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.839 ## Degrees of freedom 6 ## P-value (Chi-square) 0.442 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## ext6 1.000 1.747 ## ext8 1.000 1.747 ## ext10 1.000 1.747 ## ext12 1.000 1.747 ## ext14 1.000 1.747 ## slp =~ ## ext6 0.000 0.000 ## ext8 2.000 0.358 ## ext10 4.000 0.716 ## ext12 6.000 1.073 ## ext14 8.000 1.431 ## inv =~ ## ext6 0.000 0.000 ## ext8 0.667 1.816 ## ext10 0.800 2.179 ## ext12 0.857 2.335 ## ext14 0.875 2.384 ## Std.all ## ## 1.099 ## 0.925 ## 0.855 ## 0.830 ## 0.799 ## ## 0.000 ## 0.189 ## 0.350 ## 0.510 ## 0.654 ## ## 0.000 ## 0.962 ## 1.066 ## 1.109 ## 1.090 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp 0.175 0.141 1.240 0.215 0.560 ## inv -3.251 3.076 -1.057 0.290 -0.683 ## slp ~~ ## inv -0.335 0.302 -1.109 0.267 -0.688 ## Std.all ## ## 0.560 ## -0.683 ## ## -0.688 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 0.000 0.000 ## .ext8 0.000 0.000 ## .ext10 0.000 0.000 ## .ext12 0.000 0.000 ## .ext14 0.000 0.000 ## int 1.551 0.091 17.075 0.000 0.887 ## slp 0.014 0.030 0.458 0.647 0.076 ## inv 0.513 0.217 2.368 0.018 0.188 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.887 ## 0.076 ## 0.188 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 -0.523 1.838 -0.285 0.776 -0.523 ## .ext8 1.617 0.240 6.739 0.000 1.617 ## .ext10 1.811 0.203 8.939 0.000 1.811 ## .ext12 1.696 0.227 7.461 0.000 1.696 ## .ext14 1.582 0.447 3.541 0.000 1.582 ## int 3.052 1.850 1.650 0.099 1.000 ## slp 0.032 0.033 0.978 0.328 1.000 ## inv 7.422 5.288 1.404 0.160 1.000 ## Std.all ## -0.207 ## 0.453 ## 0.433 ## 0.383 ## 0.331 ## 1.000 ## 1.000 ## 1.000 lavTestLRT(lin.lcm.fit, inv.lcm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## inv.lcm.fit 6 5272.6 5328.6 5.8386 ## lin.lcm.fit 10 5278.2 5318.3 19.5065 13.668 4 0.008434 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that we are comparing the inverse and linear models, not the inverse and quadratic. This is because while the linear model is nested within both quadratic and inverse models, the two are not nested with respect to one another. However, we might graphically examine the trends implied by the model for a moment. What should be visually apparent is that we get quite a few flips in the direction of curvature in the inverse compared to the quadratic model. Indeed the quadratic effect is negative (\\(-0.015\\)) and the inverse effect is positive (\\(0.513\\)). This sensitivity is likely another indication that curvature is really over-fitting noise in these data rather than reflecting some true non-linearity. Below are how to achieve this model with the MLM: external.math.long$age_inv &lt;- 1 - (external.math.long$age + 1)^(-1) inv.mlm &lt;- lmer(ext ~ 1 + age + age_inv + (1 + age + age_inv | id), na.action = na.omit, REML = TRUE, data = external.math.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(inv.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: ext ~ 1 + age + age_inv + (1 + age + age_inv | id) ## Data: external.math.long ## Control: ## lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 5257.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2607 -0.5446 -0.1801 0.4579 4.1099 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.83374 0.9131 ## age 0.01219 0.1104 0.20 ## age_inv 0.90843 0.9531 0.51 -0.17 ## Residual 1.72232 1.3124 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.56085 0.09081 319.40873 17.188 &lt;2e-16 *** ## age 0.01432 0.02980 283.39325 0.480 0.6313 ## age_inv 0.49152 0.21733 353.09910 2.262 0.0243 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(lin.mlm, inv.mlm) ## Data: external.math.long ## Models: ## lin.mlm: ext ~ 1 + age + (1 + age | id) ## inv.mlm: ext ~ 1 + age + age_inv + (1 + age + age_inv | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## lin.mlm 6 5271.7 5303 -2629.9 5259.7 ## inv.mlm 10 5266.9 5319 -2623.4 5246.9 12.825 4 0.01216 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 and LCSM (note that the subtraction method gets a little messy for the slope loadings): inv.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pext6 =~ 1*ext6; ext6 ~ 0; ext6 ~~ ext6; pext6 ~~ 0*pext6 pext8 =~ 1*ext8; ext8 ~ 0; ext8 ~~ ext8; pext8 ~~ 0*pext8 pext10 =~ 1*ext10; ext10 ~ 0; ext10 ~~ ext10; pext10 ~~ 0*pext10 pext12 =~ 1*ext12; ext12 ~ 0; ext12 ~~ ext12; pext12 ~~ 0*pext12 pext14 =~ 1*ext14; ext14 ~ 0; ext14 ~~ ext14; pext14 ~~ 0*pext14 # Regressions Between Adjacent Observations pext8 ~ 1*pext6 pext10 ~ 1*pext8 pext12 ~ 1*pext10 pext14 ~ 1*pext12 # Define Change Latent Variables (delta) delta21 =~ 1*pext8; delta21 ~~ 0*delta21 delta32 =~ 1*pext10; delta32 ~~ 0*delta32 delta43 =~ 1*pext12; delta43 ~~ 0*delta43 delta54 =~ 1*pext14; delta54 ~~ 0*delta54 # Define Intercept and Slope int =~ 1*pext6 slp =~ 2*delta21 + 2*delta32 + 2*delta43 + 2*delta54 inv =~ (2/3)*delta21 + (2/15)*delta32 + (2/35)*delta43 + (1/56)*delta54 int ~ 1 slp ~ 1 inv ~ 1 int ~~ slp int ~~ inv slp ~~ slp slp ~~ inv inv ~~ inv &quot; inv.lcsm.fit &lt;- sem(inv.lcsm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(inv.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 64 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.839 ## Degrees of freedom 6 ## P-value (Chi-square) 0.442 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pext6 =~ ## ext6 1.000 1.747 ## pext8 =~ ## ext8 1.000 1.397 ## pext10 =~ ## ext10 1.000 1.539 ## pext12 =~ ## ext12 1.000 1.655 ## pext14 =~ ## ext14 1.000 1.790 ## delta21 =~ ## pext8 1.000 1.140 ## delta32 =~ ## pext10 1.000 0.185 ## delta43 =~ ## pext12 1.000 0.166 ## delta54 =~ ## pext14 1.000 0.182 ## int =~ ## pext6 1.000 1.000 ## slp =~ ## delta21 2.000 0.225 ## delta32 2.000 1.255 ## delta43 2.000 1.301 ## delta54 2.000 1.097 ## inv =~ ## delta21 0.667 1.141 ## delta32 0.133 1.274 ## delta43 0.057 0.566 ## delta54 0.018 0.149 ## Std.all ## ## 1.099 ## ## 0.739 ## ## 0.753 ## ## 0.786 ## ## 0.818 ## ## 1.140 ## ## 0.185 ## ## 0.166 ## ## 0.182 ## ## 1.000 ## ## 0.225 ## 1.255 ## 1.301 ## 1.097 ## ## 1.141 ## 1.274 ## 0.566 ## 0.149 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pext8 ~ ## pext6 1.000 1.251 ## pext10 ~ ## pext8 1.000 0.908 ## pext12 ~ ## pext10 1.000 0.930 ## pext14 ~ ## pext12 1.000 0.925 ## Std.all ## ## 1.251 ## ## 0.908 ## ## 0.930 ## ## 0.925 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp 0.175 0.141 1.240 0.215 0.560 ## inv -3.251 3.076 -1.057 0.290 -0.683 ## slp ~~ ## inv -0.335 0.302 -1.109 0.267 -0.688 ## Std.all ## ## 0.560 ## -0.683 ## ## -0.688 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 0.000 0.000 ## .ext8 0.000 0.000 ## .ext10 0.000 0.000 ## .ext12 0.000 0.000 ## .ext14 0.000 0.000 ## int 1.551 0.091 17.075 0.000 0.887 ## slp 0.014 0.030 0.458 0.647 0.076 ## inv 0.513 0.217 2.368 0.018 0.188 ## .pext6 0.000 0.000 ## .pext8 0.000 0.000 ## .pext10 0.000 0.000 ## .pext12 0.000 0.000 ## .pext14 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 0.000 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.887 ## 0.076 ## 0.188 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .ext6 -0.523 1.838 -0.285 0.776 -0.523 ## .pext6 0.000 0.000 ## .ext8 1.617 0.240 6.739 0.000 1.617 ## .pext8 0.000 0.000 ## .ext10 1.811 0.203 8.939 0.000 1.811 ## .pext10 0.000 0.000 ## .ext12 1.696 0.227 7.461 0.000 1.696 ## .pext12 0.000 0.000 ## .ext14 1.582 0.447 3.541 0.000 1.582 ## .pext14 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 0.000 ## slp 0.032 0.033 0.978 0.328 1.000 ## inv 7.422 5.288 1.404 0.160 1.000 ## int 3.052 1.850 1.650 0.099 1.000 ## Std.all ## -0.207 ## 0.000 ## 0.453 ## 0.000 ## 0.433 ## 0.000 ## 0.383 ## 0.000 ## 0.331 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.000 ## 1.000 ## 1.000 lavTestLRT(lin.lcsm.fit, inv.lcsm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## inv.lcsm.fit 6 5272.6 5328.6 5.8386 ## lin.lcsm.fit 10 5278.2 5318.3 19.5065 13.668 4 0.008434 ## ## inv.lcsm.fit ## lin.lcsm.fit ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Piecewise Trajectories If we do not think that a single polynomial function can sufficiently capture a complex trajectory, we might consider bolting two (or more) polynomial functions together using a piecewise approach. Here we will use the adversity data which covers \\(8\\) years of childhood (ages \\(4-11\\)). The simplest piecewise trajectory can be constructed two distinct linear pieces joined at a knot point. We need at least 3 time points to specify a line but the pieces can share a time point at the knot point. This means we need a minimum of \\(5\\) time points in order to fit even the simplest piecewise model. Note that with this minimum, the knot point is constrained to be at the middle time point, and the knot can never be placed at the first or last two time points because of the 3 time point requirement to estimate the linear slope. Note that as we discussed before, these time point requirements can be accomodated at the group level, and no one individual need be observed \\(5\\) or more times. Indeed this is the case here, where no individual is measured more than \\(4\\) times. There are two general approaches for specifying piecewise models. The first, and more common, approach is the two-rate specification, where each effect can be interpreted in isolation like a regular linear model. We specify the two-rate LCM using the syntax below. Note that we code the factor loadings in such a way that the intercept is at the knot point (age 8). two.rate &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp1 =~ -3*fmin4 + -2*fmin5 + -1*fmin6 + 0*fmin7 + 0*fmin8 + 0*fmin9 + 0*fmin10 + 0*fmin11 slp2 =~ 0*fmin4 + 0*fmin5 + 0*fmin6 + 0*fmin7 + 1*fmin8 + 2*fmin9 + 3*fmin10 + 4*fmin11 &quot; two.rate.fit &lt;- growth(two.rate, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(two.rate.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 50 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 17 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 35.322 ## Degrees of freedom 27 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## fmin4 1.000 0.886 ## fmin5 1.000 0.886 ## fmin6 1.000 0.886 ## fmin7 1.000 0.886 ## fmin8 1.000 0.886 ## fmin9 1.000 0.886 ## fmin10 1.000 0.886 ## fmin11 1.000 0.886 ## slp1 =~ ## fmin4 -3.000 -0.985 ## fmin5 -2.000 -0.657 ## fmin6 -1.000 -0.328 ## fmin7 0.000 0.000 ## fmin8 0.000 0.000 ## fmin9 0.000 0.000 ## fmin10 0.000 0.000 ## fmin11 0.000 0.000 ## slp2 =~ ## fmin4 0.000 0.000 ## fmin5 0.000 0.000 ## fmin6 0.000 0.000 ## fmin7 0.000 0.000 ## fmin8 1.000 0.068 ## fmin9 2.000 0.136 ## fmin10 3.000 0.204 ## fmin11 4.000 0.272 ## Std.all ## ## 0.888 ## 0.942 ## 0.824 ## 0.761 ## 0.706 ## 0.720 ## 0.739 ## 0.661 ## ## -0.987 ## -0.698 ## -0.305 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.054 ## 0.111 ## 0.170 ## 0.203 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp1 0.138 0.062 2.233 0.026 0.475 ## slp2 0.027 0.045 0.602 0.547 0.449 ## slp1 ~~ ## slp2 0.011 0.019 0.548 0.584 0.475 ## Std.all ## ## 0.475 ## 0.449 ## ## 0.475 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.000 0.000 ## .fmin5 0.000 0.000 ## .fmin6 0.000 0.000 ## .fmin7 0.000 0.000 ## .fmin8 0.000 0.000 ## .fmin9 0.000 0.000 ## .fmin10 0.000 0.000 ## .fmin11 0.000 0.000 ## int 0.216 0.062 3.495 0.000 0.244 ## slp1 0.079 0.029 2.741 0.006 0.239 ## slp2 0.031 0.020 1.576 0.115 0.455 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.244 ## 0.239 ## 0.455 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.069 0.388 0.178 0.859 0.069 ## .fmin5 0.221 0.190 1.161 0.246 0.221 ## .fmin6 0.539 0.103 5.231 0.000 0.539 ## .fmin7 0.570 0.156 3.653 0.000 0.570 ## .fmin8 0.731 0.129 5.671 0.000 0.731 ## .fmin9 0.605 0.099 6.108 0.000 0.605 ## .fmin10 0.450 0.123 3.664 0.000 0.450 ## .fmin11 0.722 0.172 4.191 0.000 0.722 ## int 0.786 0.151 5.215 0.000 1.000 ## slp1 0.108 0.056 1.919 0.055 1.000 ## slp2 0.005 0.019 0.240 0.810 1.000 ## Std.all ## 0.069 ## 0.250 ## 0.466 ## 0.420 ## 0.464 ## 0.399 ## 0.312 ## 0.401 ## 1.000 ## 1.000 ## 1.000 ggplot(data.frame(id=two.rate.fit@Data@case.idx[[1]], lavPredict(two.rate.fit,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(fmin)(.+)&quot;) %&gt;% dplyr::mutate(age = as.numeric(age)), aes(x = age, y = fmin, group = id, color = factor(id))) + geom_line() + labs(title = &quot;2-Rate Piecewise LCM Trajectories&quot;, x = &quot;Age&quot;, y = &quot;Predicted Forceps Minor Microstructure&quot;) + theme(legend.position = &quot;none&quot;) add.rate &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp1 =~ -3*fmin4 + -2*fmin5 + -1*fmin6 + 0*fmin7 + 1*fmin8 + 2*fmin9 + 3*fmin10 + 4*fmin11 slp2 =~ 0*fmin4 + 0*fmin5 + 0*fmin6 + 0*fmin7 + 1*fmin8 + 2*fmin9 + 3*fmin10 + 4*fmin11 &quot; add.rate.fit &lt;- growth(add.rate, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(add.rate.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 44 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 17 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 35.322 ## Degrees of freedom 27 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## fmin4 1.000 0.886 ## fmin5 1.000 0.886 ## fmin6 1.000 0.886 ## fmin7 1.000 0.886 ## fmin8 1.000 0.886 ## fmin9 1.000 0.886 ## fmin10 1.000 0.886 ## fmin11 1.000 0.886 ## slp1 =~ ## fmin4 -3.000 -0.985 ## fmin5 -2.000 -0.657 ## fmin6 -1.000 -0.328 ## fmin7 0.000 0.000 ## fmin8 1.000 0.328 ## fmin9 2.000 0.657 ## fmin10 3.000 0.985 ## fmin11 4.000 1.314 ## slp2 =~ ## fmin4 0.000 0.000 ## fmin5 0.000 0.000 ## fmin6 0.000 0.000 ## fmin7 0.000 0.000 ## fmin8 1.000 0.302 ## fmin9 2.000 0.604 ## fmin10 3.000 0.906 ## fmin11 4.000 1.209 ## Std.all ## ## 0.888 ## 0.942 ## 0.824 ## 0.761 ## 0.706 ## 0.720 ## 0.739 ## 0.661 ## ## -0.987 ## -0.698 ## -0.305 ## 0.000 ## 0.262 ## 0.533 ## 0.821 ## 0.980 ## ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.241 ## 0.491 ## 0.755 ## 0.901 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp1 0.138 0.062 2.233 0.026 0.475 ## slp2 -0.111 0.101 -1.099 0.272 -0.415 ## slp1 ~~ ## slp2 -0.097 0.067 -1.441 0.149 -0.980 ## Std.all ## ## 0.475 ## -0.415 ## ## -0.980 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.000 0.000 ## .fmin5 0.000 0.000 ## .fmin6 0.000 0.000 ## .fmin7 0.000 0.000 ## .fmin8 0.000 0.000 ## .fmin9 0.000 0.000 ## .fmin10 0.000 0.000 ## .fmin11 0.000 0.000 ## int 0.216 0.062 3.495 0.000 0.244 ## slp1 0.079 0.029 2.741 0.006 0.239 ## slp2 -0.048 0.041 -1.150 0.250 -0.157 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.244 ## 0.239 ## -0.157 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.069 0.388 0.178 0.859 0.069 ## .fmin5 0.221 0.190 1.161 0.246 0.221 ## .fmin6 0.539 0.103 5.231 0.000 0.539 ## .fmin7 0.570 0.156 3.653 0.000 0.570 ## .fmin8 0.731 0.129 5.671 0.000 0.731 ## .fmin9 0.605 0.099 6.108 0.000 0.605 ## .fmin10 0.450 0.123 3.664 0.000 0.450 ## .fmin11 0.722 0.172 4.191 0.000 0.722 ## int 0.786 0.151 5.215 0.000 1.000 ## slp1 0.108 0.056 1.919 0.055 1.000 ## slp2 0.091 0.094 0.968 0.333 1.000 ## Std.all ## 0.069 ## 0.250 ## 0.466 ## 0.420 ## 0.464 ## 0.399 ## 0.312 ## 0.401 ## 1.000 ## 1.000 ## 1.000 trials &lt;- read.csv(&quot;data/trials.csv&quot;) quad.rate &lt;- &quot;int =~ 1*trial.1 + 1*trial.2 + 1*trial.3 + 1*trial.4 + 1*trial.5 + 1*trial.6 + 1*trial.7 slp1 =~ -3*trial.1 + -2*trial.2 + -1*trial.3 + 0*trial.4 + 0*trial.5 + 0*trial.6 + 0*trial.7 quad =~ 9*trial.1 + 4*trial.2 + 1*trial.3 + 0*trial.4 + 0*trial.5 + 0*trial.6 + 0*trial.7 slp2 =~ 0*trial.1 + 0*trial.2 + 0*trial.3 + 0*trial.4 + 1*trial.5 + 2*trial.6 + 3*trial.7 &quot; quad.rate.fit &lt;- growth(quad.rate, data = trials, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(quad.rate.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 55 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 297 ## Number of missing patterns 2 ## ## Model Test User Model: ## ## Test statistic 46.778 ## Degrees of freedom 14 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int =~ ## trial.1 1.000 0.900 ## trial.2 1.000 0.900 ## trial.3 1.000 0.900 ## trial.4 1.000 0.900 ## trial.5 1.000 0.900 ## trial.6 1.000 0.900 ## trial.7 1.000 0.900 ## slp1 =~ ## trial.1 -3.000 -0.846 ## trial.2 -2.000 -0.564 ## trial.3 -1.000 -0.282 ## trial.4 0.000 0.000 ## trial.5 0.000 0.000 ## trial.6 0.000 0.000 ## trial.7 0.000 0.000 ## quad =~ ## trial.1 9.000 1.028 ## trial.2 4.000 0.457 ## trial.3 1.000 0.114 ## trial.4 0.000 0.000 ## trial.5 0.000 0.000 ## trial.6 0.000 0.000 ## trial.7 0.000 0.000 ## slp2 =~ ## trial.1 0.000 0.000 ## trial.2 0.000 0.000 ## trial.3 0.000 0.000 ## trial.4 0.000 0.000 ## trial.5 1.000 0.167 ## trial.6 2.000 0.333 ## trial.7 3.000 0.500 ## Std.all ## ## 0.904 ## 0.866 ## 0.821 ## 0.830 ## 0.819 ## 0.780 ## 0.718 ## ## -0.851 ## -0.543 ## -0.257 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## 1.033 ## 0.440 ## 0.104 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.152 ## 0.289 ## 0.399 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## int ~~ ## slp1 -0.067 0.061 -1.099 0.272 -0.264 ## quad -0.044 0.019 -2.275 0.023 -0.426 ## slp2 -0.001 0.024 -0.042 0.967 -0.007 ## slp1 ~~ ## quad 0.029 0.027 1.060 0.289 0.895 ## slp2 0.007 0.023 0.292 0.770 0.140 ## quad ~~ ## slp2 0.003 0.007 0.393 0.694 0.140 ## Std.all ## ## -0.264 ## -0.426 ## -0.007 ## ## 0.895 ## 0.140 ## ## 0.140 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .trial.1 0.000 0.000 ## .trial.2 0.000 0.000 ## .trial.3 0.000 0.000 ## .trial.4 0.000 0.000 ## .trial.5 0.000 0.000 ## .trial.6 0.000 0.000 ## .trial.7 0.000 0.000 ## int 0.416 0.060 6.956 0.000 0.463 ## slp1 -0.052 0.052 -1.006 0.314 -0.184 ## quad -0.065 0.017 -3.709 0.000 -0.566 ## slp2 0.164 0.020 8.193 0.000 0.983 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.463 ## -0.184 ## -0.566 ## 0.983 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .trial.1 0.350 0.115 3.047 0.002 0.350 ## .trial.2 0.285 0.036 7.954 0.000 0.285 ## .trial.3 0.311 0.039 7.983 0.000 0.311 ## .trial.4 0.365 0.049 7.506 0.000 0.365 ## .trial.5 0.370 0.037 9.896 0.000 0.370 ## .trial.6 0.414 0.044 9.298 0.000 0.414 ## .trial.7 0.517 0.071 7.249 0.000 0.517 ## int 0.810 0.091 8.930 0.000 1.000 ## slp1 0.080 0.079 1.010 0.312 1.000 ## quad 0.013 0.011 1.193 0.233 1.000 ## slp2 0.028 0.012 2.334 0.020 1.000 ## Std.all ## 0.354 ## 0.265 ## 0.259 ## 0.311 ## 0.307 ## 0.311 ## 0.329 ## 1.000 ## 1.000 ## 1.000 ## 1.000 ggplot(data.frame(id=quad.rate.fit@Data@case.idx[[1]], lavPredict(quad.rate.fit,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;trial&quot;), names_to = c(&quot;.value&quot;, &quot;num&quot;), names_pattern = &quot;(trial).(.)&quot;) %&gt;% dplyr::mutate(trial = as.numeric(trial)), aes(x = num, y = trial, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Inverse LCM Trajectories&quot;, x = &quot;Age&quot;, y = &quot;Predicted Externalizing Behavior&quot;) + theme(legend.position = &quot;none&quot;) adversity.long &lt;- adversity %&gt;% pivot_longer(cols = starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(fmin)(.+)&quot;) %&gt;% mutate(age = as.numeric(age), slp1 = ifelse(age &gt; 7, 0, age - 7), slp2 = ifelse(age &lt; 7, 0, age - 7), quad = ifelse(age &gt; 7, 0, (age - 7)^2)) two.rate.mlm &lt;- lmer(fmin ~ 1 + slp1 + slp2 + (1 + slp1 + slp2 | id), na.action = na.omit, REML = TRUE, data = adversity.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(two.rate.mlm) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: fmin ~ 1 + slp1 + slp2 + (1 + slp1 + slp2 | id) ## Data: adversity.long ## Control: ## lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 3565.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2040 -0.5616 -0.2004 0.4489 3.9715 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.766249 0.8754 ## slp1 0.020429 0.1429 1.00 ## slp2 0.006305 0.0794 0.42 0.42 ## Residual 0.635271 0.7970 ## Number of obs: 1240, groups: id, 398 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.21114 0.06180 403.53944 3.417 0.000698 *** ## slp1 0.07239 0.02774 555.66344 2.610 0.009304 ** ## slp2 0.03752 0.01968 335.58079 1.907 0.057417 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) slp1 ## slp1 0.676 ## slp2 -0.450 -0.486 ## optimizer (bobyqa) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular two.rate.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pfmin4 =~ 1*fmin4; fmin4 ~ 0; fmin4 ~~ fmin4; pfmin4 ~~ 0*fmin4 pfmin5 =~ 1*fmin5; fmin5 ~ 0; fmin5 ~~ fmin5; pfmin5 ~~ 0*fmin5 pfmin6 =~ 1*fmin6; fmin6 ~ 0; fmin6 ~~ fmin6; pfmin6 ~~ 0*fmin6 pfmin7 =~ 1*fmin7; fmin7 ~ 0; fmin7 ~~ fmin7; pfmin7 ~~ 0*fmin7 pfmin8 =~ 1*fmin8; fmin8 ~ 0; fmin8 ~~ fmin8; pfmin8 ~~ 0*fmin8 pfmin9 =~ 1*fmin9; fmin9 ~ 0; fmin9 ~~ fmin9; pfmin9 ~~ 0*fmin9 pfmin10 =~ 1*fmin10; fmin10 ~ 0; fmin10 ~~ fmin10; pfmin10 ~~ 0*fmin10 pfmin11 =~ 1*fmin11; fmin11 ~ 0; fmin11 ~~ fmin11; pfmin11 ~~ 0*fmin11 # Regressions Between Adjacent Observations pfmin4 ~ 1*pfmin5 # temporal order reversed before intercept pfmin5 ~ 1*pfmin6 pfmin6 ~ 1*pfmin7 pfmin8 ~ 1*pfmin7 # intercept time point appears twice pfmin9 ~ 1*pfmin8 pfmin10 ~ 1*pfmin9 pfmin11 ~ 1*pfmin10 # Define Change Latent Variables (delta) # loadings prior to the intercept are negative delta21 =~ -1*pfmin4; delta21 ~~ 0*delta21 delta32 =~ -1*pfmin5; delta32 ~~ 0*delta32 delta43 =~ -1*pfmin6; delta43 ~~ 0*delta43 # loadings after the intercept are as usual delta54 =~ 1*pfmin8; delta54 ~~ 0*delta54 delta65 =~ 1*pfmin9; delta65 ~~ 0*delta65 delta76 =~ 1*pfmin10; delta76 ~~ 0*delta76 delta87 =~ 1*pfmin11; delta87 ~~ 0*delta87 # Define Intercept and Slope int =~ 1*pfmin7 slp1 =~ 1*delta21 + 1*delta32 + 1*delta43 slp2 =~ 1*delta54 + 1*delta65 + 1*delta76 + 1*delta87 int ~ 1; slp1 ~ 1; slp2 ~ 1 slp1 ~~ slp1 slp2 ~~ slp2 int ~~ slp1 + slp2 slp1 ~~ slp2 &quot; two.rate.lcsm.fit &lt;- sem(two.rate.lcsm, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(two.rate.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 50 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 17 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 35.322 ## Degrees of freedom 27 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pfmin4 =~ ## fmin4 1.000 0.963 ## pfmin5 =~ ## fmin5 1.000 0.815 ## pfmin6 =~ ## fmin6 1.000 0.786 ## pfmin7 =~ ## fmin7 1.000 0.886 ## pfmin8 =~ ## fmin8 1.000 0.919 ## pfmin9 =~ ## fmin9 1.000 0.955 ## pfmin10 =~ ## fmin10 1.000 0.995 ## pfmin11 =~ ## fmin11 1.000 1.038 ## delta21 =~ ## pfmin4 -1.000 -0.341 ## delta32 =~ ## pfmin5 -1.000 -0.403 ## delta43 =~ ## pfmin6 -1.000 -0.418 ## delta54 =~ ## pfmin8 1.000 0.074 ## delta65 =~ ## pfmin9 1.000 0.071 ## delta76 =~ ## pfmin10 1.000 0.068 ## delta87 =~ ## pfmin11 1.000 0.066 ## int =~ ## pfmin7 1.000 1.000 ## slp1 =~ ## delta21 1.000 1.000 ## delta32 1.000 1.000 ## delta43 1.000 1.000 ## slp2 =~ ## delta54 1.000 1.000 ## delta65 1.000 1.000 ## delta76 1.000 1.000 ## delta87 1.000 1.000 ## Std.all ## ## 0.965 ## ## 0.866 ## ## 0.731 ## ## 0.761 ## ## 0.732 ## ## 0.776 ## ## 0.829 ## ## 0.774 ## ## -0.341 ## ## -0.403 ## ## -0.418 ## ## 0.074 ## ## 0.071 ## ## 0.068 ## ## 0.066 ## ## 1.000 ## ## 1.000 ## 1.000 ## 1.000 ## ## 1.000 ## 1.000 ## 1.000 ## 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pfmin4 ~ ## pfmin5 1.000 0.846 ## pfmin5 ~ ## pfmin6 1.000 0.964 ## pfmin6 ~ ## pfmin7 1.000 1.128 ## pfmin8 ~ ## pfmin7 1.000 0.965 ## pfmin9 ~ ## pfmin8 1.000 0.962 ## pfmin10 ~ ## pfmin9 1.000 0.960 ## pfmin11 ~ ## pfmin10 1.000 0.959 ## Std.all ## ## 0.846 ## ## 0.964 ## ## 1.128 ## ## 0.965 ## ## 0.962 ## ## 0.960 ## ## 0.959 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .pfmin4 ~~ ## .fmin4 0.000 NaN ## .pfmin5 ~~ ## .fmin5 0.000 NaN ## .pfmin6 ~~ ## .fmin6 0.000 NaN ## .pfmin7 ~~ ## .fmin7 0.000 NaN ## .pfmin8 ~~ ## .fmin8 0.000 NaN ## .pfmin9 ~~ ## .fmin9 0.000 NaN ## .pfmin10 ~~ ## .fmin10 0.000 NaN ## .pfmin11 ~~ ## .fmin11 0.000 NaN ## int ~~ ## slp1 0.138 0.062 2.233 0.026 0.475 ## slp2 0.027 0.045 0.602 0.547 0.449 ## slp1 ~~ ## slp2 0.011 0.019 0.548 0.584 0.475 ## Std.all ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## 0.475 ## 0.449 ## ## 0.475 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.000 0.000 ## .fmin5 0.000 0.000 ## .fmin6 0.000 0.000 ## .fmin7 0.000 0.000 ## .fmin8 0.000 0.000 ## .fmin9 0.000 0.000 ## .fmin10 0.000 0.000 ## .fmin11 0.000 0.000 ## int 0.216 0.062 3.495 0.000 0.244 ## slp1 0.079 0.029 2.741 0.006 0.239 ## slp2 0.031 0.020 1.576 0.115 0.455 ## .pfmin4 0.000 0.000 ## .pfmin5 0.000 0.000 ## .pfmin6 0.000 0.000 ## .pfmin7 0.000 0.000 ## .pfmin8 0.000 0.000 ## .pfmin9 0.000 0.000 ## .pfmin10 0.000 0.000 ## .pfmin11 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 0.000 ## .delta65 0.000 0.000 ## .delta76 0.000 0.000 ## .delta87 0.000 0.000 ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.244 ## 0.239 ## 0.455 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.069 0.388 0.178 0.859 0.069 ## .fmin5 0.221 0.190 1.161 0.246 0.221 ## .fmin6 0.539 0.103 5.231 0.000 0.539 ## .fmin7 0.570 0.156 3.653 0.000 0.570 ## .fmin8 0.731 0.129 5.671 0.000 0.731 ## .fmin9 0.605 0.099 6.108 0.000 0.605 ## .fmin10 0.450 0.123 3.664 0.000 0.450 ## .fmin11 0.722 0.172 4.191 0.000 0.722 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 0.000 ## .delta65 0.000 0.000 ## .delta76 0.000 0.000 ## .delta87 0.000 0.000 ## slp1 0.108 0.056 1.919 0.055 1.000 ## slp2 0.005 0.019 0.240 0.810 1.000 ## .pfmin4 0.000 0.000 ## .pfmin5 0.000 0.000 ## .pfmin6 0.000 0.000 ## .pfmin7 0.000 0.000 ## .pfmin8 0.000 0.000 ## .pfmin9 0.000 0.000 ## .pfmin10 0.000 0.000 ## .pfmin11 0.000 0.000 ## int 0.786 0.151 5.215 0.000 1.000 ## Std.all ## 0.069 ## 0.250 ## 0.466 ## 0.420 ## 0.464 ## 0.399 ## 0.312 ## 0.401 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.000 ## 1.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.000 two.rate.prop.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pfmin4 =~ 1*fmin4; fmin4 ~ 0; fmin4 ~~ fmin4; pfmin4 ~~ 0*fmin4 pfmin5 =~ 1*fmin5; fmin5 ~ 0; fmin5 ~~ fmin5; pfmin5 ~~ 0*fmin5 pfmin6 =~ 1*fmin6; fmin6 ~ 0; fmin6 ~~ fmin6; pfmin6 ~~ 0*fmin6 pfmin7 =~ 1*fmin7; fmin7 ~ 0; fmin7 ~~ fmin7; pfmin7 ~~ 0*fmin7 pfmin8 =~ 1*fmin8; fmin8 ~ 0; fmin8 ~~ fmin8; pfmin8 ~~ 0*fmin8 pfmin9 =~ 1*fmin9; fmin9 ~ 0; fmin9 ~~ fmin9; pfmin9 ~~ 0*fmin9 pfmin10 =~ 1*fmin10; fmin10 ~ 0; fmin10 ~~ fmin10; pfmin10 ~~ 0*fmin10 pfmin11 =~ 1*fmin11; fmin11 ~ 0; fmin11 ~~ fmin11; pfmin11 ~~ 0*fmin11 # Regressions Between Adjacent Observations pfmin4 ~ 1*pfmin5 # temporal order reversed before intercept pfmin5 ~ 1*pfmin6 pfmin6 ~ 1*pfmin7 pfmin8 ~ 1*pfmin7 # intercept time point appears twice pfmin9 ~ 1*pfmin8 pfmin10 ~ 1*pfmin9 pfmin11 ~ 1*pfmin10 # Define Change Latent Variables (delta) # loadings prior to the intercept are negative delta21 =~ -1*pfmin4; delta21 ~~ 0*delta21 delta32 =~ -1*pfmin5; delta32 ~~ 0*delta32 delta43 =~ -1*pfmin6; delta43 ~~ 0*delta43 # loadings after the intercept are as usual delta54 =~ 1*pfmin8; delta54 ~~ 0*delta54 delta65 =~ 1*pfmin9; delta65 ~~ 0*delta65 delta76 =~ 1*pfmin10; delta76 ~~ 0*delta76 delta87 =~ 1*pfmin11; delta87 ~~ 0*delta87 # Define Proportional Change Regressions (beta = equality constraint) # Nonrecursive Proportional Paths delta21 ~ beta*pfmin4 delta32 ~ beta*pfmin5 delta43 ~ beta*pfmin6 # Standard Proportional Paths delta54 ~ beta*pfmin7 delta65 ~ beta*pfmin8 delta76 ~ beta*pfmin9 delta87 ~ beta*pfmin10 # Define Intercept and Slope int =~ 1*pfmin7 slp1 =~ 1*delta21 + 1*delta32 + 1*delta43 slp2 =~ 1*delta54 + 1*delta65 + 1*delta76 + 1*delta87 int ~ 1; slp1 ~ 1; slp2 ~ 1 slp1 ~~ slp1 slp2 ~~ slp2 int ~~ slp1 + slp2 slp1 ~~ slp2 &quot; two.rate.prop.lcsm.fit &lt;- sem(two.rate.prop.lcsm, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(two.rate.prop.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-9 ended normally after 773 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 24 ## Number of equality constraints 6 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 34.156 ## Degrees of freedom 26 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pfmin4 =~ ## fmin4 1.000 0.763 ## pfmin5 =~ ## fmin5 1.000 0.747 ## pfmin6 =~ ## fmin6 1.000 0.741 ## pfmin7 =~ ## fmin7 1.000 0.881 ## pfmin8 =~ ## fmin8 1.000 0.893 ## pfmin9 =~ ## fmin9 1.000 0.919 ## pfmin10 =~ ## fmin10 1.000 0.974 ## pfmin11 =~ ## fmin11 1.000 1.070 ## delta21 =~ ## pfmin4 -1.000 -0.103 ## delta32 =~ ## pfmin5 -1.000 -0.242 ## delta43 =~ ## pfmin6 -1.000 -0.560 ## delta54 =~ ## pfmin8 1.000 NA ## delta65 =~ ## pfmin9 1.000 NA ## delta76 =~ ## pfmin10 1.000 NA ## delta87 =~ ## pfmin11 1.000 NA ## int =~ ## pfmin7 1.000 1.000 ## slp1 =~ ## delta21 1.000 12.917 ## delta32 1.000 5.618 ## delta43 1.000 2.444 ## slp2 =~ ## delta54 1.000 NA ## delta65 1.000 NA ## delta76 1.000 NA ## delta87 1.000 NA ## Std.all ## ## 0.741 ## ## 0.800 ## ## 0.705 ## ## 0.747 ## ## 0.720 ## ## 0.757 ## ## 0.820 ## ## 0.779 ## ## -0.103 ## ## -0.242 ## ## -0.560 ## ## NA ## ## NA ## ## NA ## ## NA ## ## 1.000 ## ## 12.917 ## 5.618 ## 2.444 ## ## NA ## NA ## NA ## NA ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## pfmin4 ~ ## pfmin5 1.000 0.979 ## pfmin5 ~ ## pfmin6 1.000 0.992 ## pfmin6 ~ ## pfmin7 1.000 1.189 ## pfmin8 ~ ## pfmin7 1.000 0.986 ## pfmin9 ~ ## pfmin8 1.000 0.971 ## pfmin10 ~ ## pfmin9 1.000 0.944 ## pfmin11 ~ ## pfmin10 1.000 0.910 ## delta21 ~ ## pfmin4 (beta) 1.299 1.790 0.725 0.468 12.627 ## delta32 ~ ## pfmin5 (beta) 1.299 1.790 0.725 0.468 5.377 ## delta43 ~ ## pfmin6 (beta) 1.299 1.790 0.725 0.468 2.320 ## delta54 ~ ## pfmin7 (beta) 1.299 1.790 0.725 0.468 NA ## delta65 ~ ## pfmin8 (beta) 1.299 1.790 0.725 0.468 NA ## delta76 ~ ## pfmin9 (beta) 1.299 1.790 0.725 0.468 NA ## delta87 ~ ## pfmin10 (beta) 1.299 1.790 0.725 0.468 NA ## Std.all ## ## 0.979 ## ## 0.992 ## ## 1.189 ## ## 0.986 ## ## 0.971 ## ## 0.944 ## ## 0.910 ## ## 12.627 ## ## 5.377 ## ## 2.320 ## ## NA ## ## NA ## ## NA ## ## NA ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .pfmin4 ~~ ## .fmin4 0.000 NaN ## .pfmin5 ~~ ## .fmin5 0.000 NaN ## .pfmin6 ~~ ## .fmin6 0.000 NaN ## .pfmin7 ~~ ## .fmin7 0.000 NaN ## .pfmin8 ~~ ## .fmin8 0.000 NaN ## .pfmin9 ~~ ## .fmin9 0.000 NaN ## .pfmin10 ~~ ## .fmin10 0.000 NaN ## .pfmin11 ~~ ## .fmin11 0.000 NaN ## int ~~ ## slp1 -0.550 0.925 -0.594 0.552 -0.615 ## slp2 -0.997 1.445 -0.690 0.490 -1.000 ## slp1 ~~ ## slp2 0.713 2.177 0.327 0.743 0.621 ## Std.all ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## NaN ## ## -0.615 ## -1.000 ## ## 0.621 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.000 0.000 ## .fmin5 0.000 0.000 ## .fmin6 0.000 0.000 ## .fmin7 0.000 0.000 ## .fmin8 0.000 0.000 ## .fmin9 0.000 0.000 ## .fmin10 0.000 0.000 ## .fmin11 0.000 0.000 ## int 0.212 0.058 3.626 0.000 0.241 ## slp1 -0.026 0.156 -0.165 0.869 -0.025 ## slp2 -0.265 0.410 -0.647 0.518 -0.234 ## .pfmin4 0.000 0.000 ## .pfmin5 0.000 0.000 ## .pfmin6 0.000 0.000 ## .pfmin7 0.000 0.000 ## .pfmin8 0.000 0.000 ## .pfmin9 0.000 0.000 ## .pfmin10 0.000 0.000 ## .pfmin11 0.000 0.000 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 NA ## .delta65 0.000 NA ## .delta76 0.000 NA ## .delta87 0.000 NA ## Std.all ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.241 ## -0.025 ## -0.234 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## NA ## NA ## NA ## NA ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv ## .fmin4 0.478 0.284 1.685 0.092 0.478 ## .fmin5 0.315 0.203 1.550 0.121 0.315 ## .fmin6 0.555 0.112 4.945 0.000 0.555 ## .fmin7 0.613 0.118 5.190 0.000 0.613 ## .fmin8 0.743 0.136 5.478 0.000 0.743 ## .fmin9 0.630 0.102 6.191 0.000 0.630 ## .fmin10 0.463 0.121 3.840 0.000 0.463 ## .fmin11 0.742 0.500 1.483 0.138 0.742 ## .delta21 0.000 0.000 ## .delta32 0.000 0.000 ## .delta43 0.000 0.000 ## .delta54 0.000 NA ## .delta65 0.000 NA ## .delta76 0.000 NA ## .delta87 0.000 NA ## slp1 1.029 2.469 0.417 0.677 1.000 ## slp2 1.281 3.663 0.350 0.726 1.000 ## .pfmin4 0.000 0.000 ## .pfmin5 0.000 0.000 ## .pfmin6 0.000 0.000 ## .pfmin7 0.000 0.000 ## .pfmin8 0.000 0.000 ## .pfmin9 0.000 0.000 ## .pfmin10 0.000 0.000 ## .pfmin11 0.000 0.000 ## int 0.776 0.114 6.816 0.000 1.000 ## Std.all ## 0.451 ## 0.361 ## 0.502 ## 0.441 ## 0.482 ## 0.427 ## 0.328 ## 0.393 ## 0.000 ## 0.000 ## 0.000 ## NA ## NA ## NA ## NA ## 1.000 ## 1.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 0.000 ## 1.000 Nonlinear Trajectories MLM: show negatively accelerated exponential GAMM: full GAMM with b-splines LCM: Show 2 free-loading forms LCSM: dual-change model Additional Considerations Fixed and Random Effects show in accelerated (braintime) data that we can estimate a quadratic overall trend even though no one has 4 observations Generalizability Code for cross-validiation? "],["05-covariates.html", "Covariates and Distal Outcomes Covariates Distal Outcomes", " Covariates and Distal Outcomes Including covariates and distal outcomes into our models. Covariates Time Invariant Covariates Show with MLM/GAMM/LCM Need to check if TICs are possible with LCSMs (something Patrick said makes me think no) latent TIC? joint likelihood Time Varying Covariates Show with MLM/GAMM/LCM LCM: show unique time-specific relationships show fixed vs random effects show contemporaneous and lagged effects Cross-level Interactions Show with MLM and LCM Within- and Betwen-Person Variance show approaches to centering in the MLM show RI-CLPM/LCM-SR model Multivariate Models Show with MLM/LCM/LCSM Distal Outcomes MLM: show 2 step model LCM: show simultaneous model and 2 step model "],["06-nesting.html", "Nested Data Categorical Predictors Multiple Groups Models Fixed Effect Approach Random Effect Approach Cluster Correction", " Nested Data Different forms of nesting in longitudinal models. Categorical Predictors Show with MLM/LCM Multiple Groups Models Show with LCM/LCSM Fixed Effect Approach Show with MLM Random Effect Approach Show with MLM &amp; LCM ML-SEM Cluster Correction Cluster correction: link to Mplus code "],["07-datasets.html", "Datasets", " Datasets Description of datasets used in the code companion "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
